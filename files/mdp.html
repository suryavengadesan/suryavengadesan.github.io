<!DOCTYPE html>

<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="mobile-web-app-capable" content="yes">
    <title>
        What are MDPs? And how can we Solve them? - HackMD
    </title>
    <link rel="icon" type="image/png" href="https://hackmd.io/favicon.png">
    <link rel="apple-touch-icon" href="https://hackmd.io/apple-touch-icon.png">

    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha256-916EbMg70RQy9LHiGkXzG8hSg9EdNy97GazNG/aiY1w=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/ionicons/2.0.1/css/ionicons.min.css" integrity="sha256-3iu9jgsy9TpTwXKb7bNQzqWekRX7pPK+2OLj3R922fo=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/octicons/3.5.0/octicons.min.css" integrity="sha256-QiWfLIsCT02Sdwkogf6YMiQlj4NE84MKkzEMkZnMGdg=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.5.1/themes/prism.min.css" integrity="sha256-vtR0hSWRc3Tb26iuN2oZHt3KRUomwTufNIf5/4oeCyg=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@hackmd/emojify.js@2.1.0/dist/css/basic/emojify.min.css" integrity="sha256-UOrvMOsSDSrW6szVLe8ZDZezBxh5IoIfgTwdNDgTjiU=" crossorigin="anonymous" />
    <style>
        @import url(https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,500,500i|Source+Code+Pro:300,400,500|Source+Sans+Pro:300,300i,400,400i,600,600i|Source+Serif+Pro&subset=latin-ext);.hljs{display:block;background:#fff;padding:.5em;color:#333;overflow-x:auto}.hljs-comment,.hljs-meta{color:#969896}.hljs-emphasis,.hljs-quote,.hljs-string,.hljs-strong,.hljs-template-variable,.hljs-variable{color:#df5000}.hljs-keyword,.hljs-selector-tag,.hljs-type{color:#a71d5d}.hljs-attribute,.hljs-bullet,.hljs-literal,.hljs-number,.hljs-symbol{color:#0086b3}.hljs-built_in,.hljs-builtin-name{color:#005cc5}.hljs-name,.hljs-section{color:#63a35c}.hljs-tag{color:#333}.hljs-attr,.hljs-selector-attr,.hljs-selector-class,.hljs-selector-id,.hljs-selector-pseudo,.hljs-title{color:#795da3}.hljs-addition{color:#55a532;background-color:#eaffea}.hljs-deletion{color:#bd2c00;background-color:#ffecec}.hljs-link{text-decoration:underline}.markdown-body{font-size:16px;line-height:1.5;word-wrap:break-word}.markdown-body:after,.markdown-body:before{display:table;content:""}.markdown-body:after{clear:both}.markdown-body>:first-child{margin-top:0!important}.markdown-body>:last-child{margin-bottom:0!important}.markdown-body a:not([href]){color:inherit;text-decoration:none}.markdown-body .absent{color:#c00}.markdown-body .anchor{float:left;padding-right:4px;margin-left:-20px;line-height:1}.markdown-body .anchor:focus{outline:none}.markdown-body blockquote,.markdown-body dl,.markdown-body ol,.markdown-body p,.markdown-body pre,.markdown-body table,.markdown-body ul{margin-top:0;margin-bottom:16px}.markdown-body hr{height:.25em;padding:0;margin:24px 0;background-color:#e7e7e7;border:0}.markdown-body blockquote{font-size:16px;padding:0 1em;color:#777;border-left:.25em solid #ddd}.markdown-body blockquote>:first-child{margin-top:0}.markdown-body blockquote>:last-child{margin-bottom:0}.markdown-body kbd,.popover kbd{display:inline-block;padding:3px 5px;font-size:11px;line-height:10px;color:#555;vertical-align:middle;background-color:#fcfcfc;border:1px solid #ccc;border-bottom-color:#bbb;border-radius:3px;box-shadow:inset 0 -1px 0 #bbb}.markdown-body .loweralpha{list-style-type:lower-alpha}.markdown-body h1,.markdown-body h2,.markdown-body h3,.markdown-body h4,.markdown-body h5,.markdown-body h6{margin-top:24px;margin-bottom:16px;font-weight:600;line-height:1.25}.markdown-body h1 .octicon-link,.markdown-body h2 .octicon-link,.markdown-body h3 .octicon-link,.markdown-body h4 .octicon-link,.markdown-body h5 .octicon-link,.markdown-body h6 .octicon-link{color:#000;vertical-align:middle;visibility:hidden}.markdown-body h1:hover .anchor,.markdown-body h2:hover .anchor,.markdown-body h3:hover .anchor,.markdown-body h4:hover .anchor,.markdown-body h5:hover .anchor,.markdown-body h6:hover .anchor{text-decoration:none}.markdown-body h1:hover .anchor .octicon-link,.markdown-body h2:hover .anchor .octicon-link,.markdown-body h3:hover .anchor .octicon-link,.markdown-body h4:hover .anchor .octicon-link,.markdown-body h5:hover .anchor .octicon-link,.markdown-body h6:hover .anchor .octicon-link{visibility:visible}.markdown-body h1 code,.markdown-body h1 tt,.markdown-body h2 code,.markdown-body h2 tt,.markdown-body h3 code,.markdown-body h3 tt,.markdown-body h4 code,.markdown-body h4 tt,.markdown-body h5 code,.markdown-body h5 tt,.markdown-body h6 code,.markdown-body h6 tt{font-size:inherit}.markdown-body h1{font-size:2em}.markdown-body h1,.markdown-body h2{padding-bottom:.3em;border-bottom:1px solid #eee}.markdown-body h2{font-size:1.5em}.markdown-body h3{font-size:1.25em}.markdown-body h4{font-size:1em}.markdown-body h5{font-size:.875em}.markdown-body h6{font-size:.85em;color:#777}.markdown-body ol,.markdown-body ul{padding-left:2em}.markdown-body ol.no-list,.markdown-body ul.no-list{padding:0;list-style-type:none}.markdown-body ol ol,.markdown-body ol ul,.markdown-body ul ol,.markdown-body ul ul{margin-top:0;margin-bottom:0}.markdown-body li>p{margin-top:16px}.markdown-body li+li{padding-top:.25em}.markdown-body dl{padding:0}.markdown-body dl dt{padding:0;margin-top:16px;font-size:1em;font-style:italic;font-weight:700}.markdown-body dl dd{padding:0 16px;margin-bottom:16px}.markdown-body table{display:block;width:100%;overflow:auto;word-break:normal;word-break:keep-all}.markdown-body table th{font-weight:700}.markdown-body table td,.markdown-body table th{padding:6px 13px;border:1px solid #ddd}.markdown-body table tr{background-color:#fff;border-top:1px solid #ccc}.markdown-body table tr:nth-child(2n){background-color:#f8f8f8}.markdown-body img{max-width:100%;box-sizing:content-box;background-color:#fff}.markdown-body img[align=right]{padding-left:20px}.markdown-body img[align=left]{padding-right:20px}.markdown-body .emoji{max-width:none;vertical-align:text-top;background-color:transparent}.markdown-body span.frame{display:block;overflow:hidden}.markdown-body span.frame>span{display:block;float:left;width:auto;padding:7px;margin:13px 0 0;overflow:hidden;border:1px solid #ddd}.markdown-body span.frame span img{display:block;float:left}.markdown-body span.frame span span{display:block;padding:5px 0 0;clear:both;color:#333}.markdown-body span.align-center{display:block;overflow:hidden;clear:both}.markdown-body span.align-center>span{display:block;margin:13px auto 0;overflow:hidden;text-align:center}.markdown-body span.align-center span img{margin:0 auto;text-align:center}.markdown-body span.align-right{display:block;overflow:hidden;clear:both}.markdown-body span.align-right>span{display:block;margin:13px 0 0;overflow:hidden;text-align:right}.markdown-body span.align-right span img{margin:0;text-align:right}.markdown-body span.float-left{display:block;float:left;margin-right:13px;overflow:hidden}.markdown-body span.float-left span{margin:13px 0 0}.markdown-body span.float-right{display:block;float:right;margin-left:13px;overflow:hidden}.markdown-body span.float-right>span{display:block;margin:13px auto 0;overflow:hidden;text-align:right}.markdown-body code,.markdown-body tt{padding:0;padding-top:.2em;padding-bottom:.2em;margin:0;font-size:85%;background-color:rgba(0,0,0,.04);border-radius:3px}.markdown-body code:after,.markdown-body code:before,.markdown-body tt:after,.markdown-body tt:before{letter-spacing:-.2em;content:"\00a0"}.markdown-body code br,.markdown-body tt br{display:none}.markdown-body del code{text-decoration:inherit}.markdown-body pre{word-wrap:normal}.markdown-body pre>code{padding:0;margin:0;font-size:100%;word-break:normal;white-space:pre;background:transparent;border:0}.markdown-body .highlight{margin-bottom:16px}.markdown-body .highlight pre{margin-bottom:0;word-break:normal}.markdown-body .highlight pre,.markdown-body pre{padding:16px;overflow:auto;font-size:85%;line-height:1.45;background-color:#f7f7f7;border-radius:3px}.markdown-body pre code,.markdown-body pre tt{display:inline;max-width:auto;padding:0;margin:0;overflow:visible;line-height:inherit;word-wrap:normal;background-color:transparent;border:0}.markdown-body pre code:after,.markdown-body pre code:before,.markdown-body pre tt:after,.markdown-body pre tt:before{content:normal}.markdown-body .csv-data td,.markdown-body .csv-data th{padding:5px;overflow:hidden;font-size:12px;line-height:1;text-align:left;white-space:nowrap}.markdown-body .csv-data .blob-line-num{padding:10px 8px 9px;text-align:right;background:#fff;border:0}.markdown-body .csv-data tr{border-top:0}.markdown-body .csv-data th{font-weight:700;background:#f8f8f8;border-top:0}.news .alert .markdown-body blockquote{padding:0 0 0 40px;border:0 none}.activity-tab .news .alert .commits,.activity-tab .news .markdown-body blockquote{padding-left:0}.task-list-item{list-style-type:none}.task-list-item label{font-weight:400}.task-list-item.enabled label{cursor:pointer}.task-list-item+.task-list-item{margin-top:3px}.task-list-item-checkbox{float:left;margin:.31em 0 .2em -1.3em!important;vertical-align:middle;cursor:default!important}.markdown-body{padding-top:40px;padding-bottom:40px;max-width:758px;overflow:visible!important;position:relative}.markdown-body .emoji{vertical-align:top}.markdown-body pre{border:inherit!important}.markdown-body code{color:inherit!important}.markdown-body pre code .wrapper{display:-moz-inline-flex;display:-ms-inline-flex;display:-o-inline-flex;display:inline-flex}.markdown-body pre code .gutter{float:left;overflow:hidden;-webkit-user-select:none;user-select:none}.markdown-body pre code .gutter.linenumber{text-align:right;position:relative;display:inline-block;cursor:default;z-index:4;padding:0 8px 0 0;min-width:20px;box-sizing:content-box;color:#afafaf!important;border-right:3px solid #6ce26c!important}.markdown-body pre code .gutter.linenumber>span:before{content:attr(data-linenumber)}.markdown-body pre code .code{float:left;margin:0 0 0 16px}.markdown-body .gist .line-numbers{border-left:none;border-top:none;border-bottom:none}.markdown-body .gist .line-data{border:none}.markdown-body .gist table{border-spacing:0;border-collapse:inherit!important}.markdown-body code[data-gist-id]{background:none;padding:0}.markdown-body code[data-gist-id]:after,.markdown-body code[data-gist-id]:before{content:""}.markdown-body code[data-gist-id] .blob-num{border:unset}.markdown-body code[data-gist-id] table{overflow:unset;margin-bottom:unset}.markdown-body code[data-gist-id] table tr{background:unset}.markdown-body[dir=rtl] pre{direction:ltr}.markdown-body[dir=rtl] code{direction:ltr;unicode-bidi:embed}.markdown-body .alert>p:last-child{margin-bottom:0}.markdown-body pre.abc,.markdown-body pre.flow-chart,.markdown-body pre.graphviz,.markdown-body pre.mermaid,.markdown-body pre.sequence-diagram,.markdown-body pre.vega{text-align:center;background-color:inherit;border-radius:0;white-space:inherit;overflow:visible}.markdown-body pre.abc>code,.markdown-body pre.flow-chart>code,.markdown-body pre.graphviz>code,.markdown-body pre.mermaid>code,.markdown-body pre.sequence-diagram>code,.markdown-body pre.vega>code{text-align:left}.markdown-body pre.abc>svg,.markdown-body pre.flow-chart>svg,.markdown-body pre.graphviz>svg,.markdown-body pre.mermaid>svg,.markdown-body pre.sequence-diagram>svg,.markdown-body pre.vega>svg{max-width:100%;height:100%}.markdown-body pre>code.wrap{white-space:pre-wrap;white-space:-moz-pre-wrap;white-space:-pre-wrap;white-space:-o-pre-wrap;word-wrap:break-word}.markdown-body .alert>p:last-child,.markdown-body .alert>ul:last-child{margin-bottom:0}.markdown-body summary{display:list-item}.markdown-body summary:focus{outline:none}.markdown-body details summary{cursor:pointer}.markdown-body details:not([open])>:not(summary){display:none}.markdown-body figure{margin:1em 40px}.markdown-body .mark,.markdown-body mark{background-color:#fff1a7}.vimeo,.youtube{cursor:pointer;display:table;text-align:center;background-position:50%;background-repeat:no-repeat;background-size:contain;background-color:#000;overflow:hidden}.vimeo,.youtube{position:relative;width:100%}.youtube{padding-bottom:56.25%}.vimeo img{width:100%;object-fit:contain;z-index:0}.youtube img{object-fit:cover;z-index:0}.vimeo iframe,.youtube iframe,.youtube img{width:100%;height:100%;position:absolute;top:0;left:0}.vimeo iframe,.youtube iframe{vertical-align:middle;z-index:1}.vimeo .icon,.youtube .icon{position:absolute;height:auto;width:auto;top:50%;left:50%;transform:translate(-50%,-50%);color:#fff;opacity:.3;transition:opacity .2s;z-index:0}.vimeo:hover .icon,.youtube:hover .icon{opacity:.6;transition:opacity .2s}.slideshare .inner,.speakerdeck .inner{position:relative;width:100%}.slideshare .inner iframe,.speakerdeck .inner iframe{position:absolute;top:0;bottom:0;left:0;right:0;width:100%;height:100%}.figma{display:table;position:relative;width:100%;padding-bottom:56.25%}.figma iframe{position:absolute;top:0;bottom:0;left:0;right:0;width:100%;height:100%;border:1px solid #eee}.markmap-container{height:300px}.markmap-container>svg{width:100%;height:100%}.MJX_Assistive_MathML{display:none}#MathJax_Message{z-index:1000!important}.ui-infobar{position:relative;z-index:2;max-width:760px;margin:25px auto -25px;color:#777}.toc .invisable-node{list-style-type:none}.ui-toc{position:fixed;bottom:20px;z-index:998}.ui-toc.both-mode{margin-left:8px}.ui-toc.both-mode .ui-toc-label{height:40px;padding:10px 4px;border-top-left-radius:0;border-bottom-left-radius:0}.ui-toc-label{background-color:#e6e6e6;border:none;color:#868686;transition:opacity .2s}.ui-toc .open .ui-toc-label{opacity:1;color:#fff;transition:opacity .2s}.ui-toc-label:focus{opacity:.3;background-color:#ccc;color:#000}.ui-toc-label:hover{opacity:1;background-color:#ccc;transition:opacity .2s}.ui-toc-dropdown{margin-top:20px;margin-bottom:20px;padding-left:10px;padding-right:10px;max-width:45vw;width:25vw;max-height:70vh;overflow:auto;text-align:inherit}.ui-toc-dropdown>.toc{max-height:calc(70vh - 100px);overflow:auto}.ui-toc-dropdown[dir=rtl] .nav{padding-right:0;letter-spacing:.0029em}.ui-toc-dropdown a{overflow:hidden;text-overflow:ellipsis;white-space:pre}.ui-toc-dropdown .nav>li>a{display:block;padding:4px 20px;font-size:13px;font-weight:500;color:#767676}.ui-toc-dropdown .nav>li:first-child:last-child>ul,.ui-toc-dropdown .toc.expand ul{display:block}.ui-toc-dropdown .nav>li>a:focus,.ui-toc-dropdown .nav>li>a:hover{padding-left:19px;color:#000;text-decoration:none;background-color:transparent;border-left:1px solid #000}.ui-toc-dropdown[dir=rtl] .nav>li>a:focus,.ui-toc-dropdown[dir=rtl] .nav>li>a:hover{padding-right:19px;border-left:none;border-right:1px solid #000}.ui-toc-dropdown .nav>.active:focus>a,.ui-toc-dropdown .nav>.active:hover>a,.ui-toc-dropdown .nav>.active>a{padding-left:18px;font-weight:700;color:#000;background-color:transparent;border-left:2px solid #000}.ui-toc-dropdown[dir=rtl] .nav>.active:focus>a,.ui-toc-dropdown[dir=rtl] .nav>.active:hover>a,.ui-toc-dropdown[dir=rtl] .nav>.active>a{padding-right:18px;border-left:none;border-right:2px solid #000}.ui-toc-dropdown .nav .nav{display:none;padding-bottom:10px}.ui-toc-dropdown .nav>.active>ul{display:block}.ui-toc-dropdown .nav .nav>li>a{padding-top:1px;padding-bottom:1px;padding-left:30px;font-size:12px;font-weight:400}.ui-toc-dropdown[dir=rtl] .nav .nav>li>a{padding-right:30px}.ui-toc-dropdown .nav .nav>li>ul>li>a{padding-top:1px;padding-bottom:1px;padding-left:40px;font-size:12px;font-weight:400}.ui-toc-dropdown[dir=rtl] .nav .nav>li>ul>li>a{padding-right:40px}.ui-toc-dropdown .nav .nav>li>a:focus,.ui-toc-dropdown .nav .nav>li>a:hover{padding-left:29px}.ui-toc-dropdown[dir=rtl] .nav .nav>li>a:focus,.ui-toc-dropdown[dir=rtl] .nav .nav>li>a:hover{padding-right:29px}.ui-toc-dropdown .nav .nav>li>ul>li>a:focus,.ui-toc-dropdown .nav .nav>li>ul>li>a:hover{padding-left:39px}.ui-toc-dropdown[dir=rtl] .nav .nav>li>ul>li>a:focus,.ui-toc-dropdown[dir=rtl] .nav .nav>li>ul>li>a:hover{padding-right:39px}.ui-toc-dropdown .nav .nav>.active:focus>a,.ui-toc-dropdown .nav .nav>.active:hover>a,.ui-toc-dropdown .nav .nav>.active>a{padding-left:28px;font-weight:500}.ui-toc-dropdown[dir=rtl] .nav .nav>.active:focus>a,.ui-toc-dropdown[dir=rtl] .nav .nav>.active:hover>a,.ui-toc-dropdown[dir=rtl] .nav .nav>.active>a{padding-right:28px}.ui-toc-dropdown .nav .nav>.active>.nav>.active:focus>a,.ui-toc-dropdown .nav .nav>.active>.nav>.active:hover>a,.ui-toc-dropdown .nav .nav>.active>.nav>.active>a{padding-left:38px;font-weight:500}.ui-toc-dropdown[dir=rtl] .nav .nav>.active>.nav>.active:focus>a,.ui-toc-dropdown[dir=rtl] .nav .nav>.active>.nav>.active:hover>a,.ui-toc-dropdown[dir=rtl] .nav .nav>.active>.nav>.active>a{padding-right:38px}.markdown-body{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Helvetica Neue,Helvetica,Roboto,Arial,sans-serif}html[lang^=ja] .markdown-body{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Helvetica Neue,Helvetica,Roboto,Arial,Hiragino Kaku Gothic Pro,ヒラギノ角ゴ Pro W3,Osaka,Meiryo,メイリオ,MS Gothic,ＭＳ\ ゴシック,sans-serif}html[lang=zh-tw] .markdown-body{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Helvetica Neue,Helvetica,Roboto,Arial,PingFang TC,Microsoft JhengHei,微軟正黑,sans-serif}html[lang=zh-cn] .markdown-body{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Helvetica Neue,Helvetica,Roboto,Arial,PingFang SC,Microsoft YaHei,微软雅黑,sans-serif}html .markdown-body[lang^=ja]{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Helvetica Neue,Helvetica,Roboto,Arial,Hiragino Kaku Gothic Pro,ヒラギノ角ゴ Pro W3,Osaka,Meiryo,メイリオ,MS Gothic,ＭＳ\ ゴシック,sans-serif}html .markdown-body[lang=zh-tw]{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Helvetica Neue,Helvetica,Roboto,Arial,PingFang TC,Microsoft JhengHei,微軟正黑,sans-serif}html .markdown-body[lang=zh-cn]{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Helvetica Neue,Helvetica,Roboto,Arial,PingFang SC,Microsoft YaHei,微软雅黑,sans-serif}html[lang^=ja] .ui-toc-dropdown{font-family:Source Sans Pro,Helvetica,Arial,Meiryo UI,MS PGothic,ＭＳ\ Ｐゴシック,sans-serif}html[lang=zh-tw] .ui-toc-dropdown{font-family:Source Sans Pro,Helvetica,Arial,Microsoft JhengHei UI,微軟正黑UI,sans-serif}html[lang=zh-cn] .ui-toc-dropdown{font-family:Source Sans Pro,Helvetica,Arial,Microsoft YaHei UI,微软雅黑UI,sans-serif}html .ui-toc-dropdown[lang^=ja]{font-family:Source Sans Pro,Helvetica,Arial,Meiryo UI,MS PGothic,ＭＳ\ Ｐゴシック,sans-serif}html .ui-toc-dropdown[lang=zh-tw]{font-family:Source Sans Pro,Helvetica,Arial,Microsoft JhengHei UI,微軟正黑UI,sans-serif}html .ui-toc-dropdown[lang=zh-cn]{font-family:Source Sans Pro,Helvetica,Arial,Microsoft YaHei UI,微软雅黑UI,sans-serif}.ui-affix-toc{position:fixed;top:0;max-width:15vw;max-height:70vh;overflow:auto}.back-to-top,.expand-toggle,.go-to-bottom{display:block;padding:4px 10px;margin-top:10px;margin-left:10px;font-size:12px;font-weight:500;color:#999}.back-to-top:focus,.back-to-top:hover,.expand-toggle:focus,.expand-toggle:hover,.go-to-bottom:focus,.go-to-bottom:hover{color:#563d7c;text-decoration:none}.back-to-top,.go-to-bottom{margin-top:0}.ui-user-icon{width:20px;height:20px;display:block;border-radius:50%;margin-top:2px;margin-bottom:2px;margin-right:5px;background-position:50%;background-repeat:no-repeat;background-size:cover}.ui-user-icon.small{width:18px;height:18px;display:inline-block;vertical-align:middle;margin:0 0 .2em}.ui-infobar>small>span{line-height:22px}.ui-infobar>small .dropdown{display:inline-block}.ui-infobar>small .dropdown a:focus,.ui-infobar>small .dropdown a:hover{text-decoration:none}.ui-more-info{color:#888;cursor:pointer;vertical-align:middle}.ui-more-info .fa{font-size:16px}.ui-connectedGithub,.ui-published-note{color:#888}.ui-connectedGithub{line-height:23px;white-space:nowrap}.ui-connectedGithub a.file-path{color:#888;text-decoration:none;padding-left:22px}.ui-connectedGithub a.file-path:active,.ui-connectedGithub a.file-path:hover{color:#888;text-decoration:underline}.ui-connectedGithub .fa{font-size:20px}.ui-published-note .fa{font-size:20px;vertical-align:top}.unselectable{-webkit-user-select:none;-o-user-select:none;user-select:none}.selectable{-webkit-user-select:text;-o-user-select:text;user-select:text}.inline-spoiler-section{cursor:pointer}.inline-spoiler-section .spoiler-text{border-radius:2px;background-color:#333}.inline-spoiler-section .spoiler-text>*{opacity:0}.inline-spoiler-section .spoiler-img{filter:blur(10px)}.inline-spoiler-section.raw{border-radius:2px;background-color:#333}.inline-spoiler-section.raw>*{opacity:0}.inline-spoiler-section.unveil{cursor:auto}.inline-spoiler-section.unveil .spoiler-text{background-color:rgba(51,51,51,.1)}.inline-spoiler-section.unveil .spoiler-text>*{opacity:1}.inline-spoiler-section.unveil .spoiler-img{filter:none}@media print{blockquote,div,img,pre,table{page-break-inside:avoid!important}a[href]:after{font-size:12px!important}}.markdown-body.slides{position:relative;z-index:1;color:#222}.markdown-body.slides:before{content:"";display:block;position:absolute;top:0;left:0;right:0;bottom:0;z-index:-1;background-color:currentColor;box-shadow:0 0 0 50vw}.markdown-body.slides section[data-markdown]{position:relative;margin-bottom:1.5em;background-color:#fff;text-align:center}.markdown-body.slides section[data-markdown] code{text-align:left}.markdown-body.slides section[data-markdown]:before{content:"";display:block;padding-bottom:56.23%}.markdown-body.slides section[data-markdown]>div:first-child{position:absolute;top:50%;left:1em;right:1em;transform:translateY(-50%);max-height:100%;overflow:hidden}.markdown-body.slides section[data-markdown]>ul{display:inline-block}.markdown-body.slides>section>section+section:after{content:"";position:absolute;top:-1.5em;right:1em;height:1.5em;border:3px solid #777}.site-ui-font{font-family:Source Sans Pro,Helvetica,Arial,sans-serif}html[lang^=ja] .site-ui-font{font-family:Source Sans Pro,Helvetica,Arial,Hiragino Kaku Gothic Pro,ヒラギノ角ゴ Pro W3,Osaka,Meiryo,メイリオ,MS Gothic,ＭＳ\ ゴシック,sans-serif}html[lang=zh-tw] .site-ui-font{font-family:Source Sans Pro,Helvetica,Arial,PingFang TC,Microsoft JhengHei,微軟正黑,sans-serif}html[lang=zh-cn] .site-ui-font{font-family:Source Sans Pro,Helvetica,Arial,PingFang SC,Microsoft YaHei,微软雅黑,sans-serif}body{font-smoothing:subpixel-antialiased!important;-webkit-font-smoothing:subpixel-antialiased!important;-moz-osx-font-smoothing:auto!important;-webkit-overflow-scrolling:touch;letter-spacing:.025em;font-family:Source Sans Pro,Helvetica,Arial,sans-serif}html[lang^=ja] body{font-family:Source Sans Pro,Helvetica,Arial,Hiragino Kaku Gothic Pro,ヒラギノ角ゴ Pro W3,Osaka,Meiryo,メイリオ,MS Gothic,ＭＳ\ ゴシック,sans-serif}html[lang=zh-tw] body{font-family:Source Sans Pro,Helvetica,Arial,PingFang TC,Microsoft JhengHei,微軟正黑,sans-serif}html[lang=zh-cn] body{font-family:Source Sans Pro,Helvetica,Arial,PingFang SC,Microsoft YaHei,微软雅黑,sans-serif}abbr[title]{border-bottom:none;text-decoration:underline;-webkit-text-decoration:underline dotted;text-decoration:underline dotted}abbr[data-original-title],abbr[title]{cursor:help}body.modal-open{overflow-y:auto;padding-right:0!important}svg{text-shadow:none}
    </style>
    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
    	<script src="https://cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.min.js" integrity="sha256-3Jy/GbSLrg0o9y5Z5n1uw0qxZECH7C6OQpVBgNFYa0g=" crossorigin="anonymous"></script>
    	<script src="https://cdnjs.cloudflare.com/ajax/libs/respond.js/1.4.2/respond.min.js" integrity="sha256-g6iAfvZp+nDQ2TdTR/VVKJf3bGro4ub5fvWSWVRi2NE=" crossorigin="anonymous"></script>
		<script src="https://cdnjs.cloudflare.com/ajax/libs/es5-shim/4.5.9/es5-shim.min.js" integrity="sha256-8E4Is26QH0bD52WoQpcB+R/tcWQtpzlCojrybUd7Mxo=" crossorigin="anonymous"></script>
    <![endif]-->
</head>

<body>
    <div id="doc" class="markdown-body container-fluid comment-inner comment-enabled" data-hard-breaks="true"><h1 id="What-are-MDPs-And-how-can-we-Solve-them" data-id="What-are-MDPs-And-how-can-we-Solve-them"><a class="anchor hidden-xs" href="#What-are-MDPs-And-how-can-we-Solve-them" title="What-are-MDPs-And-how-can-we-Solve-them"><span class="octicon octicon-link"></span></a><span>What are MDPs? And how can we Solve them?</span></h1><h4 id="by-Surya-Vengadesan" data-id="by-Surya-Vengadesan"><a class="anchor hidden-xs" href="#by-Surya-Vengadesan" title="by-Surya-Vengadesan"><span class="octicon octicon-link"></span></a><span>by Surya Vengadesan</span></h4><h2 id="Introduction" data-id="Introduction"><a class="anchor hidden-xs" href="#Introduction" title="Introduction"><span class="octicon octicon-link"></span></a><span>Introduction</span></h2><p><span>With deep reinforcment learning’s success in beating humans at games including Go, Dota 2, and even Poker, there is a lot of excitement around the field and people want to understand its algorithms from the ground up. In this blog post, we will do just that. We will explore a fundamental building block of deep RL: Markov Decision Processess – a framework that models how an agent behaves and learns from it’s environment. In particular, we will lay out the theory of MDPs and explore approximate methods for solving them.</span></p><h3 id="Mr-Markov-Navigating-College" data-id="Mr-Markov-Navigating-College"><a class="anchor hidden-xs" href="#Mr-Markov-Navigating-College" title="Mr-Markov-Navigating-College"><span class="octicon octicon-link"></span></a><span>Mr. Markov Navigating College</span></h3><p><span>Now, let’s walk through MDPs by studying a specific agent. Specifically, an agent is an entity that interacts within its environment and interatively learns how to best act within the environment. For our example, Mr. Markov will be our agent; he is an undergraduate studying mathematics. Markov needs to make many decisions while in college (his environment). In a typical day, Markov studies for his probability theory class, sleeps in his bed, or socializes with his friends in hour long chunks. Markov is faced with a problem. Some days Markov is incredibly tired from staying up to finish his problem sets or feels stir-crazy from sitting at his desk for hours on end. Therefore, Markov needs a process to help him navigate through his daily decisions in hopes to bring him peace.</span></p><h3 id="Modeling-Mr-Markov’s-World" data-id="Modeling-Mr-Markov’s-World"><a class="anchor hidden-xs" href="#Modeling-Mr-Markov’s-World" title="Modeling-Mr-Markov’s-World"><span class="octicon octicon-link"></span></a><span>Modeling Mr. Markov’s World</span></h3><p><span>In this blog post we are going to help this poor student, by laying out a Markov Decision Process to model his world, then figure out what actions he should take in his best self-interest. Markov, at any given time, could be in one of a finite number of states. Let’s denote these in a set called the state space:</span></p><p><span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"></span><span id="MathJax-Element-1-Frame" class="mjx-chtml MathJax_CHTML" tabindex="0" style="font-size: 119%; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi class=&quot;MJX-tex-caligraphic&quot; mathvariant=&quot;script&quot;>S</mi></mrow></math>" role="presentation"><span id="MJXc-Node-1" class="mjx-math" aria-hidden="true"><span id="MJXc-Node-2" class="mjx-mrow"><span id="MJXc-Node-3" class="mjx-texatom"><span id="MJXc-Node-4" class="mjx-mrow"><span id="MJXc-Node-5" class="mjx-mi"><span class="mjx-char MJXc-TeX-cal-R" style="padding-top: 0.423em; padding-bottom: 0.318em; padding-right: 0.036em;">S</span></span></span></span></span></span><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow class="MJX-TeXAtom-ORD"><mi class="MJX-tex-caligraphic" mathvariant="script">S</mi></mrow></math></span></span><script type="math/tex" id="MathJax-Element-1">\mathcal{S}</script></span><span> = {</span><span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"></span><span id="MathJax-Element-2-Frame" class="mjx-chtml MathJax_CHTML" tabindex="0" style="font-size: 119%; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>s</mi><mn>1</mn></msub></math>" role="presentation"><span id="MJXc-Node-6" class="mjx-math" aria-hidden="true"><span id="MJXc-Node-7" class="mjx-mrow"><span id="MJXc-Node-8" class="mjx-msubsup"><span class="mjx-base"><span id="MJXc-Node-9" class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.213em; padding-bottom: 0.265em;">s</span></span></span><span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span id="MJXc-Node-10" class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.37em; padding-bottom: 0.318em;">1</span></span></span></span></span></span><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>s</mi><mn>1</mn></msub></math></span></span><script type="math/tex" id="MathJax-Element-2">s_1</script></span><span> (studying), </span><span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"></span><span id="MathJax-Element-3-Frame" class="mjx-chtml MathJax_CHTML" tabindex="0" style="font-size: 119%; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>s</mi><mn>2</mn></msub></math>" role="presentation"><span id="MJXc-Node-11" class="mjx-math" aria-hidden="true"><span id="MJXc-Node-12" class="mjx-mrow"><span id="MJXc-Node-13" class="mjx-msubsup"><span class="mjx-base"><span id="MJXc-Node-14" class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.213em; padding-bottom: 0.265em;">s</span></span></span><span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span id="MJXc-Node-15" class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.37em; padding-bottom: 0.318em;">2</span></span></span></span></span></span><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>s</mi><mn>2</mn></msub></math></span></span><script type="math/tex" id="MathJax-Element-3">s_2</script></span><span> (sleeping), </span><span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"></span><span id="MathJax-Element-4-Frame" class="mjx-chtml MathJax_CHTML" tabindex="0" style="font-size: 119%; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>s</mi><mn>3</mn></msub></math>" role="presentation"><span id="MJXc-Node-16" class="mjx-math" aria-hidden="true"><span id="MJXc-Node-17" class="mjx-mrow"><span id="MJXc-Node-18" class="mjx-msubsup"><span class="mjx-base"><span id="MJXc-Node-19" class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.213em; padding-bottom: 0.265em;">s</span></span></span><span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span id="MJXc-Node-20" class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.37em; padding-bottom: 0.37em;">3</span></span></span></span></span></span><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>s</mi><mn>3</mn></msub></math></span></span><script type="math/tex" id="MathJax-Element-4">s_3</script></span><span> (socializing)}</span></p><p><span>In addition, in any given state he could decide from a set of actions. Let’s denote these in a set called the action space:</span></p><p><span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"></span><span id="MathJax-Element-5-Frame" class="mjx-chtml MathJax_CHTML" tabindex="0" style="font-size: 119%; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi class=&quot;MJX-tex-caligraphic&quot; mathvariant=&quot;script&quot;>A</mi></mrow></math>" role="presentation"><span id="MJXc-Node-21" class="mjx-math" aria-hidden="true"><span id="MJXc-Node-22" class="mjx-mrow"><span id="MJXc-Node-23" class="mjx-texatom"><span id="MJXc-Node-24" class="mjx-mrow"><span id="MJXc-Node-25" class="mjx-mi"><span class="mjx-char MJXc-TeX-cal-R" style="padding-top: 0.475em; padding-bottom: 0.37em; padding-right: 0.021em;">A</span></span></span></span></span></span><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow class="MJX-TeXAtom-ORD"><mi class="MJX-tex-caligraphic" mathvariant="script">A</mi></mrow></math></span></span><script type="math/tex" id="MathJax-Element-5">\mathcal{A}</script></span><span> = {</span><span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"></span><span id="MathJax-Element-6-Frame" class="mjx-chtml MathJax_CHTML" tabindex="0" style="font-size: 119%; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>a</mi><mn>1</mn></msub></math>" role="presentation"><span id="MJXc-Node-26" class="mjx-math" aria-hidden="true"><span id="MJXc-Node-27" class="mjx-mrow"><span id="MJXc-Node-28" class="mjx-msubsup"><span class="mjx-base"><span id="MJXc-Node-29" class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.213em; padding-bottom: 0.265em;">a</span></span></span><span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span id="MJXc-Node-30" class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.37em; padding-bottom: 0.318em;">1</span></span></span></span></span></span><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>a</mi><mn>1</mn></msub></math></span></span><script type="math/tex" id="MathJax-Element-6">a_1</script></span><span> (message a friend), </span><span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"></span><span id="MathJax-Element-7-Frame" class="mjx-chtml MathJax_CHTML" tabindex="0" style="font-size: 119%; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>a</mi><mn>2</mn></msub></math>" role="presentation"><span id="MJXc-Node-31" class="mjx-math" aria-hidden="true"><span id="MJXc-Node-32" class="mjx-mrow"><span id="MJXc-Node-33" class="mjx-msubsup"><span class="mjx-base"><span id="MJXc-Node-34" class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.213em; padding-bottom: 0.265em;">a</span></span></span><span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span id="MJXc-Node-35" class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.37em; padding-bottom: 0.318em;">2</span></span></span></span></span></span><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>a</mi><mn>2</mn></msub></math></span></span><script type="math/tex" id="MathJax-Element-7">a_2</script></span><span> (read Tolstoy), </span><span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"></span><span id="MathJax-Element-8-Frame" class="mjx-chtml MathJax_CHTML" tabindex="0" style="font-size: 119%; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>a</mi><mn>3</mn></msub></math>" role="presentation"><span id="MJXc-Node-36" class="mjx-math" aria-hidden="true"><span id="MJXc-Node-37" class="mjx-mrow"><span id="MJXc-Node-38" class="mjx-msubsup"><span class="mjx-base"><span id="MJXc-Node-39" class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.213em; padding-bottom: 0.265em;">a</span></span></span><span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span id="MJXc-Node-40" class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.37em; padding-bottom: 0.37em;">3</span></span></span></span></span></span><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>a</mi><mn>3</mn></msub></math></span></span><script type="math/tex" id="MathJax-Element-8">a_3</script></span><span> (eat a snack)}</span></p><p><span>In our model world, at every hour, Markov can perform one of these three actions from any of the three states. We shall demarcate these hours of the day by variable </span><span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"></span><span id="MathJax-Element-9-Frame" class="mjx-chtml MathJax_CHTML" tabindex="0" style="font-size: 119%; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>t</mi></math>" role="presentation"><span id="MJXc-Node-41" class="mjx-math" aria-hidden="true"><span id="MJXc-Node-42" class="mjx-mrow"><span id="MJXc-Node-43" class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.423em; padding-bottom: 0.265em;">t</span></span></span></span><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>t</mi></math></span></span><script type="math/tex" id="MathJax-Element-9">t</script></span><span>. By taking an action at a specific state at a specific time </span><span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"></span><span id="MathJax-Element-10-Frame" class="mjx-chtml MathJax_CHTML" tabindex="0" style="font-size: 119%; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>t</mi></math>" role="presentation"><span id="MJXc-Node-44" class="mjx-math" aria-hidden="true"><span id="MJXc-Node-45" class="mjx-mrow"><span id="MJXc-Node-46" class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.423em; padding-bottom: 0.265em;">t</span></span></span></span><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>t</mi></math></span></span><script type="math/tex" id="MathJax-Element-10">t</script></span><span>, Markov will end up in a new state </span><span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"></span><span id="MathJax-Element-11-Frame" class="mjx-chtml MathJax_CHTML" tabindex="0" style="font-size: 119%; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msup><mi>s</mi><mo>&amp;#x2032;</mo></msup><mo>&amp;#x2208;</mo><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi class=&quot;MJX-tex-caligraphic&quot; mathvariant=&quot;script&quot;>S</mi></mrow></math>" role="presentation"><span id="MJXc-Node-47" class="mjx-math" aria-hidden="true"><span id="MJXc-Node-48" class="mjx-mrow"><span id="MJXc-Node-49" class="mjx-msup"><span class="mjx-base"><span id="MJXc-Node-50" class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.213em; padding-bottom: 0.265em;">s</span></span></span><span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span id="MJXc-Node-51" class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.265em; padding-bottom: 0.318em;">′</span></span></span></span><span id="MJXc-Node-52" class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.265em; padding-bottom: 0.37em;">∈</span></span><span id="MJXc-Node-53" class="mjx-texatom MJXc-space3"><span id="MJXc-Node-54" class="mjx-mrow"><span id="MJXc-Node-55" class="mjx-mi"><span class="mjx-char MJXc-TeX-cal-R" style="padding-top: 0.423em; padding-bottom: 0.318em; padding-right: 0.036em;">S</span></span></span></span></span></span><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi>s</mi><mo>′</mo></msup><mo>∈</mo><mrow class="MJX-TeXAtom-ORD"><mi class="MJX-tex-caligraphic" mathvariant="script">S</mi></mrow></math></span></span><script type="math/tex" id="MathJax-Element-11">s' \in \mathcal{S}</script></span><span>. We shall also define a set of non-negative probabilities for each state-action pair and it’s resulting action, </span><span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"></span><span id="MathJax-Element-12-Frame" class="mjx-chtml MathJax_CHTML" tabindex="0" style="font-size: 119%; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>P</mi><mo stretchy=&quot;false&quot;>(</mo><msup><mi>s</mi><mo>&amp;#x2032;</mo></msup><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo stretchy=&quot;false&quot;>|</mo></mrow><mi>s</mi><mo>,</mo><mi>a</mi><mo stretchy=&quot;false&quot;>)</mo><mo>&amp;#x2265;</mo><mn>0</mn></math>" role="presentation"><span id="MJXc-Node-56" class="mjx-math" aria-hidden="true"><span id="MJXc-Node-57" class="mjx-mrow"><span id="MJXc-Node-58" class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.475em; padding-bottom: 0.265em; padding-right: 0.109em;">P</span></span><span id="MJXc-Node-59" class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.475em; padding-bottom: 0.58em;">(</span></span><span id="MJXc-Node-60" class="mjx-msup"><span class="mjx-base"><span id="MJXc-Node-61" class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.213em; padding-bottom: 0.265em;">s</span></span></span><span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span id="MJXc-Node-62" class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.265em; padding-bottom: 0.318em;">′</span></span></span></span><span id="MJXc-Node-63" class="mjx-texatom"><span id="MJXc-Node-64" class="mjx-mrow"><span id="MJXc-Node-65" class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.475em; padding-bottom: 0.58em;">|</span></span></span></span><span id="MJXc-Node-66" class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.213em; padding-bottom: 0.265em;">s</span></span><span id="MJXc-Node-67" class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.155em; padding-bottom: 0.528em;">,</span></span><span id="MJXc-Node-68" class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.213em; padding-bottom: 0.265em;">a</span></span><span id="MJXc-Node-69" class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.475em; padding-bottom: 0.58em;">)</span></span><span id="MJXc-Node-70" class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.37em; padding-bottom: 0.475em;">≥</span></span><span id="MJXc-Node-71" class="mjx-mn MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.37em; padding-bottom: 0.37em;">0</span></span></span></span><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi><mo stretchy="false">(</mo><msup><mi>s</mi><mo>′</mo></msup><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><mi>s</mi><mo>,</mo><mi>a</mi><mo stretchy="false">)</mo><mo>≥</mo><mn>0</mn></math></span></span><script type="math/tex" id="MathJax-Element-12">P(s' |s, a) \geq 0</script></span><span>, and with any probability distribution these must add to 1: </span><span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"></span><span id="MathJax-Element-13-Frame" class="mjx-chtml MathJax_CHTML" tabindex="0" style="font-size: 119%; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi mathvariant=&quot;normal&quot;>&amp;#x03A3;</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><msup><mi>s</mi><mo>&amp;#x2032;</mo></msup></mrow></msub><mi>P</mi><mo stretchy=&quot;false&quot;>(</mo><msup><mi>s</mi><mo>&amp;#x2032;</mo></msup><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo stretchy=&quot;false&quot;>|</mo></mrow><mi>s</mi><mo>,</mo><mi>a</mi><mo stretchy=&quot;false&quot;>)</mo><mo>=</mo><mn>1</mn></math>" role="presentation"><span id="MJXc-Node-72" class="mjx-math" aria-hidden="true"><span id="MJXc-Node-73" class="mjx-mrow"><span id="MJXc-Node-74" class="mjx-msubsup"><span class="mjx-base"><span id="MJXc-Node-75" class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.423em; padding-bottom: 0.318em;">Σ</span></span></span><span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span id="MJXc-Node-76" class="mjx-texatom" style=""><span id="MJXc-Node-77" class="mjx-mrow"><span id="MJXc-Node-78" class="mjx-msup"><span class="mjx-base"><span id="MJXc-Node-79" class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.213em; padding-bottom: 0.265em;">s</span></span></span><span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.409em; padding-left: 0px; padding-right: 0.071em;"><span id="MJXc-Node-80" class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.265em; padding-bottom: 0.318em;">′</span></span></span></span></span></span></span></span><span id="MJXc-Node-81" class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.475em; padding-bottom: 0.265em; padding-right: 0.109em;">P</span></span><span id="MJXc-Node-82" class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.475em; padding-bottom: 0.58em;">(</span></span><span id="MJXc-Node-83" class="mjx-msup"><span class="mjx-base"><span id="MJXc-Node-84" class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.213em; padding-bottom: 0.265em;">s</span></span></span><span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span id="MJXc-Node-85" class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.265em; padding-bottom: 0.318em;">′</span></span></span></span><span id="MJXc-Node-86" class="mjx-texatom"><span id="MJXc-Node-87" class="mjx-mrow"><span id="MJXc-Node-88" class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.475em; padding-bottom: 0.58em;">|</span></span></span></span><span id="MJXc-Node-89" class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.213em; padding-bottom: 0.265em;">s</span></span><span id="MJXc-Node-90" class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.155em; padding-bottom: 0.528em;">,</span></span><span id="MJXc-Node-91" class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.213em; padding-bottom: 0.265em;">a</span></span><span id="MJXc-Node-92" class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.475em; padding-bottom: 0.58em;">)</span></span><span id="MJXc-Node-93" class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.055em; padding-bottom: 0.318em;">=</span></span><span id="MJXc-Node-94" class="mjx-mn MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.37em; padding-bottom: 0.318em;">1</span></span></span></span><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi mathvariant="normal">Σ</mi><mrow class="MJX-TeXAtom-ORD"><msup><mi>s</mi><mo>′</mo></msup></mrow></msub><mi>P</mi><mo stretchy="false">(</mo><msup><mi>s</mi><mo>′</mo></msup><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><mi>s</mi><mo>,</mo><mi>a</mi><mo stretchy="false">)</mo><mo>=</mo><mn>1</mn></math></span></span><script type="math/tex" id="MathJax-Element-13">\Sigma_{s'} P(s'|s, a) = 1</script></span><span>.</span></p><p><span>Now, we ask Markov a question: “What is your purpose? What do you value?.” Markov, an aspiring future graduate student in mathematics, responds, “To one day teach probability theory to other students and perform original research within the field.” To help this aspiring future probability theorist, let’s add a few more definitions to his decision-making framework, that can help quantify what he values. For each state-action pair and associated next state, we assign a scalar reward </span><span class="mathjax raw"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-76"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-77">r</span><span class="MJXp-mo" id="MJXp-Span-78" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msup" id="MJXp-Span-79"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-80" style="margin-right: 0.05em;">s</span><span class="MJXp-mo MJXp-script" id="MJXp-Span-81" style="vertical-align: 0.5em;">′</span></span><span class="MJXp-mrow" id="MJXp-Span-82"><span class="MJXp-mo" id="MJXp-Span-83" style="margin-left: 0.167em; margin-right: 0.167em;">|</span></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-84">s</span><span class="MJXp-mo" id="MJXp-Span-85" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-86">a</span><span class="MJXp-mo" id="MJXp-Span-87" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-88" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-89">c</span></span></span><script type="math/tex" id="MathJax-Element-14">r(s'|s, a) = c</script></span><span>. We ask Markov a follow up question: “What’s your plan? How do you plan on getting into graduate school?” He responds, “I’m going to study, study a lot.” Now, to help Markov on his journey, we add a few extra formalisms. First we formalize his </span><em><span>plan</span></em><span> into a function, and call it a policy function </span><span class="mathjax raw"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-90"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-91">π</span><span class="MJXp-mo" id="MJXp-Span-92" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-93">a</span><span class="MJXp-mrow" id="MJXp-Span-94"><span class="MJXp-mo" id="MJXp-Span-95" style="margin-left: 0.167em; margin-right: 0.167em;">|</span></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-96">s</span><span class="MJXp-mo" id="MJXp-Span-97" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><script type="math/tex" id="MathJax-Element-15">\pi(a|s)</script></span><span> that maps every state with a specific action to take.</span></p><p><span>To sum it up, say he’s in state </span><span class="mathjax raw"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-98"><span class="MJXp-msubsup" id="MJXp-Span-99"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-100" style="margin-right: 0.05em;">s</span><span class="MJXp-mn MJXp-script" id="MJXp-Span-101" style="vertical-align: -0.4em;">1</span></span><span class="MJXp-mo" id="MJXp-Span-102" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mtext" id="MJXp-Span-103">studying</span></span></span><script type="math/tex" id="MathJax-Element-16">s_1 = \text{studying}</script></span><span>, and he decided to take the action of </span><span class="mathjax raw"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-104"><span class="MJXp-msubsup" id="MJXp-Span-105"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-106" style="margin-right: 0.05em;">a</span><span class="MJXp-mn MJXp-script" id="MJXp-Span-107" style="vertical-align: -0.4em;">1</span></span><span class="MJXp-mo" id="MJXp-Span-108" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mtext" id="MJXp-Span-109">messaging a friend</span></span></span><script type="math/tex" id="MathJax-Element-17">a_1 = \text{messaging a friend}</script></span><span> according to his policy. Given </span><span class="mathjax raw"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-110"><span class="MJXp-mo" id="MJXp-Span-111" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-112"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-113" style="margin-right: 0.05em;">s</span><span class="MJXp-mn MJXp-script" id="MJXp-Span-114" style="vertical-align: -0.4em;">1</span></span><span class="MJXp-mo" id="MJXp-Span-115" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-msubsup" id="MJXp-Span-116"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-117" style="margin-right: 0.05em;">a</span><span class="MJXp-mn MJXp-script" id="MJXp-Span-118" style="vertical-align: -0.4em;">1</span></span><span class="MJXp-mo" id="MJXp-Span-119" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><script type="math/tex" id="MathJax-Element-18">(s_1, a_1)</script></span><span>, he now has the following probabilities at ending up the following states after completing the action, </span><span class="mathjax raw"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-120"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-121">t</span><span class="MJXp-mo" id="MJXp-Span-122" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-123"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-124" style="margin-right: 0.05em;">s</span><span class="MJXp-mn MJXp-script" id="MJXp-Span-125" style="vertical-align: -0.4em;">1</span></span><span class="MJXp-mo" id="MJXp-Span-126" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mtext" id="MJXp-Span-127">studying</span><span class="MJXp-mo" id="MJXp-Span-128" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mrow" id="MJXp-Span-129"><span class="MJXp-mo" id="MJXp-Span-130" style="margin-left: 0.167em; margin-right: 0.167em;">|</span></span><span class="MJXp-msubsup" id="MJXp-Span-131"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-132" style="margin-right: 0.05em;">s</span><span class="MJXp-mn MJXp-script" id="MJXp-Span-133" style="vertical-align: -0.4em;">1</span></span><span class="MJXp-mo" id="MJXp-Span-134" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-msubsup" id="MJXp-Span-135"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-136" style="margin-right: 0.05em;">a</span><span class="MJXp-mn MJXp-script" id="MJXp-Span-137" style="vertical-align: -0.4em;">1</span></span><span class="MJXp-mo" id="MJXp-Span-138" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-139" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mn" id="MJXp-Span-140">0.2</span></span></span><script type="math/tex" id="MathJax-Element-19">t(s_1 (\text{studying})| s_1, a_1)  = 0.2</script></span><span> , </span><span class="mathjax raw"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-141"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-142">t</span><span class="MJXp-mo" id="MJXp-Span-143" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-144"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-145" style="margin-right: 0.05em;">s</span><span class="MJXp-mn MJXp-script" id="MJXp-Span-146" style="vertical-align: -0.4em;">2</span></span><span class="MJXp-mo" id="MJXp-Span-147" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mtext" id="MJXp-Span-148">sleeping</span><span class="MJXp-mo" id="MJXp-Span-149" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mrow" id="MJXp-Span-150"><span class="MJXp-mo" id="MJXp-Span-151" style="margin-left: 0.167em; margin-right: 0.167em;">|</span></span><span class="MJXp-msubsup" id="MJXp-Span-152"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-153" style="margin-right: 0.05em;">s</span><span class="MJXp-mn MJXp-script" id="MJXp-Span-154" style="vertical-align: -0.4em;">1</span></span><span class="MJXp-mo" id="MJXp-Span-155" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-msubsup" id="MJXp-Span-156"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-157" style="margin-right: 0.05em;">a</span><span class="MJXp-mn MJXp-script" id="MJXp-Span-158" style="vertical-align: -0.4em;">1</span></span><span class="MJXp-mo" id="MJXp-Span-159" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-160" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mn" id="MJXp-Span-161">0.2</span></span></span><script type="math/tex" id="MathJax-Element-20">t(s_2 (\text{sleeping})|s_1, a_1) = 0.2</script></span><span>, </span><span class="mathjax raw"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-162"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-163">t</span><span class="MJXp-mo" id="MJXp-Span-164" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-165"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-166" style="margin-right: 0.05em;">s</span><span class="MJXp-mn MJXp-script" id="MJXp-Span-167" style="vertical-align: -0.4em;">3</span></span><span class="MJXp-mo" id="MJXp-Span-168" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mtext" id="MJXp-Span-169">socializing</span><span class="MJXp-mo" id="MJXp-Span-170" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mrow" id="MJXp-Span-171"><span class="MJXp-mo" id="MJXp-Span-172" style="margin-left: 0.167em; margin-right: 0.167em;">|</span></span><span class="MJXp-msubsup" id="MJXp-Span-173"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-174" style="margin-right: 0.05em;">s</span><span class="MJXp-mn MJXp-script" id="MJXp-Span-175" style="vertical-align: -0.4em;">1</span></span><span class="MJXp-mo" id="MJXp-Span-176" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-msubsup" id="MJXp-Span-177"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-178" style="margin-right: 0.05em;">a</span><span class="MJXp-mn MJXp-script" id="MJXp-Span-179" style="vertical-align: -0.4em;">1</span></span><span class="MJXp-mo" id="MJXp-Span-180" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-181" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mn" id="MJXp-Span-182">0.6</span></span></span><script type="math/tex" id="MathJax-Element-21">t(s_3 (\text{socializing})|s_1, a_1) = 0.6</script></span><span>, which add up to 1 as defined previously. Let’s also define a set of rewards that we believe best align with what Markov says he values. We can assign real values rewards to each state he next ends up in after performing action </span><span class="mathjax raw"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-183"><span class="MJXp-msubsup" id="MJXp-Span-184"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-185" style="margin-right: 0.05em;">a</span><span class="MJXp-mn MJXp-script" id="MJXp-Span-186" style="vertical-align: -0.4em;">1</span></span></span></span><script type="math/tex" id="MathJax-Element-22">a_1</script></span><span> in state </span><span class="mathjax raw"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-187"><span class="MJXp-msubsup" id="MJXp-Span-188"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-189" style="margin-right: 0.05em;">s</span><span class="MJXp-mn MJXp-script" id="MJXp-Span-190" style="vertical-align: -0.4em;">1</span></span></span></span><script type="math/tex" id="MathJax-Element-23">s_1</script></span><span>, </span><span class="mathjax raw"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-191"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-192">r</span><span class="MJXp-mo" id="MJXp-Span-193" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-194"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-195" style="margin-right: 0.05em;">s</span><span class="MJXp-mn MJXp-script" id="MJXp-Span-196" style="vertical-align: -0.4em;">1</span></span><span class="MJXp-mo" id="MJXp-Span-197" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mtext" id="MJXp-Span-198">studying</span><span class="MJXp-mo" id="MJXp-Span-199" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mrow" id="MJXp-Span-200"><span class="MJXp-mo" id="MJXp-Span-201" style="margin-left: 0.167em; margin-right: 0.167em;">|</span></span><span class="MJXp-msubsup" id="MJXp-Span-202"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-203" style="margin-right: 0.05em;">s</span><span class="MJXp-mn MJXp-script" id="MJXp-Span-204" style="vertical-align: -0.4em;">1</span></span><span class="MJXp-mo" id="MJXp-Span-205" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-msubsup" id="MJXp-Span-206"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-207" style="margin-right: 0.05em;">a</span><span class="MJXp-mn MJXp-script" id="MJXp-Span-208" style="vertical-align: -0.4em;">1</span></span><span class="MJXp-mo" id="MJXp-Span-209" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-210" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mn" id="MJXp-Span-211">10</span></span></span><script type="math/tex" id="MathJax-Element-24">r(s_1(\text{studying})|s_1, a_1) = 10</script></span><span>, </span><span class="mathjax raw"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-212"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-213">r</span><span class="MJXp-mo" id="MJXp-Span-214" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-215"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-216" style="margin-right: 0.05em;">s</span><span class="MJXp-mn MJXp-script" id="MJXp-Span-217" style="vertical-align: -0.4em;">2</span></span><span class="MJXp-mo" id="MJXp-Span-218" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mtext" id="MJXp-Span-219">sleeping</span><span class="MJXp-mo" id="MJXp-Span-220" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mrow" id="MJXp-Span-221"><span class="MJXp-mo" id="MJXp-Span-222" style="margin-left: 0.167em; margin-right: 0.167em;">|</span></span><span class="MJXp-msubsup" id="MJXp-Span-223"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-224" style="margin-right: 0.05em;">s</span><span class="MJXp-mn MJXp-script" id="MJXp-Span-225" style="vertical-align: -0.4em;">1</span></span><span class="MJXp-mo" id="MJXp-Span-226" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-msubsup" id="MJXp-Span-227"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-228" style="margin-right: 0.05em;">a</span><span class="MJXp-mn MJXp-script" id="MJXp-Span-229" style="vertical-align: -0.4em;">1</span></span><span class="MJXp-mo" id="MJXp-Span-230" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-231" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mn" id="MJXp-Span-232">5</span></span></span><script type="math/tex" id="MathJax-Element-25">r(s_2(\text{sleeping})|s_1, a_1) = 5</script></span><span>, and </span><span class="mathjax raw"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-233"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-234">r</span><span class="MJXp-mo" id="MJXp-Span-235" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-236"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-237" style="margin-right: 0.05em;">s</span><span class="MJXp-mn MJXp-script" id="MJXp-Span-238" style="vertical-align: -0.4em;">3</span></span><span class="MJXp-mo" id="MJXp-Span-239" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mtext" id="MJXp-Span-240">socializing</span><span class="MJXp-mo" id="MJXp-Span-241" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mrow" id="MJXp-Span-242"><span class="MJXp-mo" id="MJXp-Span-243" style="margin-left: 0.167em; margin-right: 0.167em;">|</span></span><span class="MJXp-msubsup" id="MJXp-Span-244"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-245" style="margin-right: 0.05em;">a</span><span class="MJXp-mn MJXp-script" id="MJXp-Span-246" style="vertical-align: -0.4em;">1</span></span><span class="MJXp-mo" id="MJXp-Span-247" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-msubsup" id="MJXp-Span-248"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-249" style="margin-right: 0.05em;">s</span><span class="MJXp-mn MJXp-script" id="MJXp-Span-250" style="vertical-align: -0.4em;">1</span></span><span class="MJXp-mo" id="MJXp-Span-251" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-252" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mn" id="MJXp-Span-253">3</span></span></span><script type="math/tex" id="MathJax-Element-26">r(s_3(\text{socializing})|a_1, s_1) = 3</script></span><span>.</span></p><p><span>Together, we have incorporated stochastic behavior and measures of value and into the framework, since each state-action pair is now mapped to a probability distribution and a set of rewards that uniquely determine each next possible state. In essence, we have just laid out the mathematical formalism for MDPs, which not only helps Markov, but more generally exists as a tool that lies at the core of many control theory applications, including reinforcement learning.</span></p><h3 id="Recap-of-Definitions" data-id="Recap-of-Definitions"><a class="anchor hidden-xs" href="#Recap-of-Definitions" title="Recap-of-Definitions"><span class="octicon octicon-link"></span></a><span>Recap of Definitions</span></h3><p><span>We have defined 4 quantities making up the tuple </span><span class="mathjax raw"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-254"><span class="MJXp-mo" id="MJXp-Span-255" style="margin-left: 0.333em; margin-right: 0.333em;">&lt;</span><span class="MJXp-mrow" id="MJXp-Span-256"><span class="MJXp-mi MJXp-cal" id="MJXp-Span-257">S</span></span><span class="MJXp-mo" id="MJXp-Span-258" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mrow" id="MJXp-Span-259"><span class="MJXp-mi MJXp-cal" id="MJXp-Span-260">A</span></span><span class="MJXp-mo" id="MJXp-Span-261" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mrow" id="MJXp-Span-262"><span class="MJXp-mi MJXp-cal" id="MJXp-Span-263">T</span></span><span class="MJXp-mo" id="MJXp-Span-264" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mrow" id="MJXp-Span-265"><span class="MJXp-mi MJXp-cal" id="MJXp-Span-266">R</span></span><span class="MJXp-mo" id="MJXp-Span-267" style="margin-left: 0.333em; margin-right: 0.333em;">&gt;</span></span></span><script type="math/tex" id="MathJax-Element-27"><\mathcal{S},\mathcal{A}, \mathcal{T}, \mathcal{R}></script></span><span>, which includes a state space, an action space, a transition function, and a reward function. In our specific example with Markov, we have 3 states, 3 rewards, and a transition and reward function that map all pairs of state-action transitions (s’|a, s) with an associated probability reward, totalling to 27 scalars each. What we have just defined above, is referred to as a </span><em><span>finite</span></em><span> MDP, because element of the tuple consists of finite sets. Below is a subset of the MDP over an arbitrary state action pair </span><span class="mathjax raw"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-268"><span class="MJXp-mo" id="MJXp-Span-269" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-270"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-271" style="margin-right: 0.05em;">s</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-272" style="vertical-align: -0.4em;">i</span></span><span class="MJXp-mo" id="MJXp-Span-273" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-msubsup" id="MJXp-Span-274"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-275" style="margin-right: 0.05em;">a</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-276" style="vertical-align: -0.4em;">i</span></span><span class="MJXp-mo" id="MJXp-Span-277" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><script type="math/tex" id="MathJax-Element-28">(s_i, a_i)</script></span><span>.</span></p><p><img src="https://i.imgur.com/0k1YOuf.png" alt="" loading="lazy"></p><p><span>Using this structure, we would like to figure out what actions we should take to get the highest reward; fortunately, there exist proven algorithms to do exactly this. We will soon attempt to solve for an optimal policy function </span><span class="mathjax raw"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-278"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-279">π</span><span class="MJXp-mo" id="MJXp-Span-280" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mo" id="MJXp-Span-281" style="margin-left: 0.267em; margin-right: 0.267em;">⋅</span><span class="MJXp-mo" id="MJXp-Span-282" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><script type="math/tex" id="MathJax-Element-29">\pi(\cdot)</script></span><span> using said algorithms in Markov’s world. Through our specific example, we are attempting to solve the old, and suprisingly relevant meme (below), but with extreme precision due to the beauty of finite MDPs.</span></p><p><img src="https://i.imgur.com/MQuNXU7.png" alt="" loading="lazy"></p><p><span>Before, we reach the solution, however, we need a few more tools defined below.</span></p><h3 id="More-Fun-Functions" data-id="More-Fun-Functions"><a class="anchor hidden-xs" href="#More-Fun-Functions" title="More-Fun-Functions"><span class="octicon octicon-link"></span></a><span>More Fun Functions</span></h3><p><span>Given these well defined transition dynamics and rewards of Markov’s model world, we can define two additional functions. The first is the state-value function. This is determined by the state Markov is currently in and also his current policy function:</span></p><p><span class="mathjax raw"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-283"><span class="MJXp-msubsup" id="MJXp-Span-284"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-285" style="margin-right: 0.05em;">v</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-286" style="vertical-align: -0.4em;">π</span></span><span class="MJXp-mo" id="MJXp-Span-287" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-288">s</span><span class="MJXp-mo" id="MJXp-Span-289" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-290" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-msubsup" id="MJXp-Span-291"><span class="MJXp-mrow" id="MJXp-Span-292" style="margin-right: 0.05em;"><span class="MJXp-mi undefined" id="MJXp-Span-293">E</span></span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-294" style="vertical-align: -0.4em;">π</span></span><span class="MJXp-mo" id="MJXp-Span-295" style="margin-left: 0em; margin-right: 0em;">[</span><span class="MJXp-msubsup" id="MJXp-Span-296"><span class="MJXp-mi" id="MJXp-Span-297" style="margin-right: 0.05em;">Σ</span><span class="MJXp-script-box" style="height: 1.86em; vertical-align: -0.64em;"><span class="MJXp-script"><span><span style="margin-bottom: -0.25em;"><span class="MJXp-mi" id="MJXp-Span-302">∞</span></span></span></span><span class="MJXp-script"><span><span style="margin-top: -0.85em;"><span class="MJXp-mrow" id="MJXp-Span-298"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-299">k</span><span class="MJXp-mo" id="MJXp-Span-300">=</span><span class="MJXp-mn" id="MJXp-Span-301">0</span></span></span></span></span></span></span><span class="MJXp-msubsup" id="MJXp-Span-303"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-304" style="margin-right: 0.05em;">γ</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-305" style="vertical-align: 0.5em;">k</span></span><span class="MJXp-msubsup" id="MJXp-Span-306"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-307" style="margin-right: 0.05em;">R</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-308" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-309">t</span><span class="MJXp-mo" id="MJXp-Span-310">+</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-311">k</span><span class="MJXp-mo" id="MJXp-Span-312">+</span><span class="MJXp-mn" id="MJXp-Span-313">1</span></span></span><span class="MJXp-mrow" id="MJXp-Span-314"><span class="MJXp-mo" id="MJXp-Span-315" style="margin-left: 0.167em; margin-right: 0.167em;">|</span></span><span class="MJXp-msubsup" id="MJXp-Span-316"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-317" style="margin-right: 0.05em;">S</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-318" style="vertical-align: -0.4em;">t</span></span><span class="MJXp-mo" id="MJXp-Span-319" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-320">s</span><span class="MJXp-mo" id="MJXp-Span-321" style="margin-left: 0em; margin-right: 0em;">]</span></span></span><script type="math/tex" id="MathJax-Element-30">v_\pi(s) = \mathbb{E}_\pi[\Sigma_{k=0}^\infty  \gamma^kR_{t+k+1}|S_t=s]</script></span></p><p><span>This can be interpreted as the long-term expected reward that Markov will receive from currently being in state </span><span class="mathjax raw"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-322"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-323">s</span></span></span><script type="math/tex" id="MathJax-Element-31">s</script></span><span> and acting according to his plan. Here, we have two random variables that </span><span class="mathjax raw"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-324"><span class="MJXp-msubsup" id="MJXp-Span-325"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-326" style="margin-right: 0.05em;">S</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-327" style="vertical-align: -0.4em;">t</span></span></span></span><script type="math/tex" id="MathJax-Element-32">S_t</script></span><span> and </span><span class="mathjax raw"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-328"><span class="MJXp-msubsup" id="MJXp-Span-329"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-330" style="margin-right: 0.05em;">R</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-331" style="vertical-align: -0.4em;">t</span></span></span></span><script type="math/tex" id="MathJax-Element-33">R_t</script></span><span> that model the state and reward the agent will be in and recieve, at time step </span><span class="mathjax raw"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-332"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-333">t</span></span></span><script type="math/tex" id="MathJax-Element-34">t</script></span><span>, if it follows the policy defined by </span><span class="mathjax raw"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-334"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-335">π</span><span class="MJXp-mo" id="MJXp-Span-336" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mo" id="MJXp-Span-337" style="margin-left: 0.267em; margin-right: 0.267em;">⋅</span><span class="MJXp-mo" id="MJXp-Span-338" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><script type="math/tex" id="MathJax-Element-35">\pi(\cdot)</script></span><span>. We have also introduced a new variable </span><span class="mathjax raw"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-339"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-340">γ</span></span></span><script type="math/tex" id="MathJax-Element-36">\gamma</script></span><span> which we call the discount rate, that can be any value from </span><span class="mathjax raw"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-341"><span class="MJXp-mn" id="MJXp-Span-342">0</span><span class="MJXp-mo" id="MJXp-Span-343" style="margin-left: 0.333em; margin-right: 0.333em;">≤</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-344">γ</span><span class="MJXp-mo" id="MJXp-Span-345" style="margin-left: 0.333em; margin-right: 0.333em;">≤</span><span class="MJXp-mn" id="MJXp-Span-346">1</span></span></span><script type="math/tex" id="MathJax-Element-37">0 \leq \gamma \leq 1</script></span><span>. The term in the expectation expands out to this form:</span></p><p><span class="mathjax raw"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-347"><span class="MJXp-msubsup" id="MJXp-Span-348"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-349" style="margin-right: 0.05em;">γ</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-350" style="vertical-align: 0.5em;">k</span></span><span class="MJXp-msubsup" id="MJXp-Span-351"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-352" style="margin-right: 0.05em;">R</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-353" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-354">t</span><span class="MJXp-mo" id="MJXp-Span-355">+</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-356">k</span><span class="MJXp-mo" id="MJXp-Span-357">+</span><span class="MJXp-mn" id="MJXp-Span-358">1</span></span></span><span class="MJXp-mo" id="MJXp-Span-359" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-msubsup" id="MJXp-Span-360"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-361" style="margin-right: 0.05em;">γ</span><span class="MJXp-mn MJXp-script" id="MJXp-Span-362" style="vertical-align: 0.5em;">0</span></span><span class="MJXp-msubsup" id="MJXp-Span-363"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-364" style="margin-right: 0.05em;">R</span><span class="MJXp-mn MJXp-script" id="MJXp-Span-365" style="vertical-align: -0.4em;">1</span></span><span class="MJXp-mo" id="MJXp-Span-366" style="margin-left: 0.267em; margin-right: 0.267em;">+</span><span class="MJXp-msubsup" id="MJXp-Span-367"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-368" style="margin-right: 0.05em;">γ</span><span class="MJXp-mn MJXp-script" id="MJXp-Span-369" style="vertical-align: 0.5em;">1</span></span><span class="MJXp-msubsup" id="MJXp-Span-370"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-371" style="margin-right: 0.05em;">R</span><span class="MJXp-mn MJXp-script" id="MJXp-Span-372" style="vertical-align: -0.4em;">2</span></span><span class="MJXp-mo" id="MJXp-Span-373" style="margin-left: 0.267em; margin-right: 0.267em;">+</span><span class="MJXp-msubsup" id="MJXp-Span-374"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-375" style="margin-right: 0.05em;">γ</span><span class="MJXp-mn MJXp-script" id="MJXp-Span-376" style="vertical-align: 0.5em;">2</span></span><span class="MJXp-msubsup" id="MJXp-Span-377"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-378" style="margin-right: 0.05em;">R</span><span class="MJXp-mn MJXp-script" id="MJXp-Span-379" style="vertical-align: -0.4em;">3</span></span><span class="MJXp-mo" id="MJXp-Span-380" style="margin-left: 0.267em; margin-right: 0.267em;">+</span><span class="MJXp-mo" id="MJXp-Span-381" style="margin-left: 0em; margin-right: 0em;">⋯</span></span></span><script type="math/tex" id="MathJax-Element-38">\gamma^k R_{t+k+1} = \gamma^0 R_1 + \gamma^1 R_2 + \gamma^2 R_3 + \cdots</script></span></p><p><span>In essence, the value of the reward gained by taking an action and landing in a new state in the future, is being reduced by a multiple of </span><span class="mathjax raw"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-382"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-383">γ</span></span></span><script type="math/tex" id="MathJax-Element-39">\gamma</script></span><span> with each time step that passes. This answers the question on how much a given reward is depriciated each </span><span class="mathjax raw"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-384"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-385">t</span></span></span><script type="math/tex" id="MathJax-Element-40">t</script></span><span> time step into the future, before it has been obtained.</span></p><p><span>Altogether, the state-value function </span><span class="mathjax raw"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-386"><span class="MJXp-msubsup" id="MJXp-Span-387"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-388" style="margin-right: 0.05em;">v</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-389" style="vertical-align: -0.4em;">π</span></span><span class="MJXp-mo" id="MJXp-Span-390" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mo" id="MJXp-Span-391" style="margin-left: 0.267em; margin-right: 0.267em;">⋅</span><span class="MJXp-mo" id="MJXp-Span-392" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><script type="math/tex" id="MathJax-Element-41">v_\pi(\cdot)</script></span><span> allows us to help Markov gauge the </span><em><span>value</span></em><span> he obtains from his tentative </span><em><span>plan</span></em><span> that we have formalized by the policy function </span><span class="mathjax raw"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-393"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-394">π</span><span class="MJXp-mo" id="MJXp-Span-395" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mo" id="MJXp-Span-396" style="margin-left: 0.267em; margin-right: 0.267em;">⋅</span><span class="MJXp-mo" id="MJXp-Span-397" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><script type="math/tex" id="MathJax-Element-42">\pi(\cdot)</script></span><span>. Now, the curious Markov asks us, “Well, assume I’m working on my probability pset and decide to go read War and Peace by Leo Tolstoy, is that a good idea?” To answer this, let’s add our final function to put Markov’s mind at rest. Let’s call it the  action-value function </span><span class="mathjax raw"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-398"><span class="MJXp-msubsup" id="MJXp-Span-399"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-400" style="margin-right: 0.05em;">q</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-401" style="vertical-align: -0.4em;">π</span></span><span class="MJXp-mo" id="MJXp-Span-402" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-403">s</span><span class="MJXp-mo" id="MJXp-Span-404" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-405">a</span><span class="MJXp-mo" id="MJXp-Span-406" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><script type="math/tex" id="MathJax-Element-43">q_\pi(s,a)</script></span><span>, which is the expected return in rewards he receives, computed similarly to the state-value function, but incorporating the reward from an initial action </span><span class="mathjax raw"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-407"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-408">a</span></span></span><script type="math/tex" id="MathJax-Element-44">a</script></span><span> instead of action </span><span class="mathjax raw"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-409"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-410">π</span><span class="MJXp-mo" id="MJXp-Span-411" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-412">s</span><span class="MJXp-mo" id="MJXp-Span-413" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><script type="math/tex" id="MathJax-Element-45">\pi(s)</script></span><span>:</span></p><p><span class="mathjax raw"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-414"><span class="MJXp-msubsup" id="MJXp-Span-415"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-416" style="margin-right: 0.05em;">q</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-417" style="vertical-align: -0.4em;">π</span></span><span class="MJXp-mo" id="MJXp-Span-418" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-419">s</span><span class="MJXp-mo" id="MJXp-Span-420" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-421">a</span><span class="MJXp-mo" id="MJXp-Span-422" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-423" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-msubsup" id="MJXp-Span-424"><span class="MJXp-mrow" id="MJXp-Span-425" style="margin-right: 0.05em;"><span class="MJXp-mi undefined" id="MJXp-Span-426">E</span></span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-427" style="vertical-align: -0.4em;">π</span></span><span class="MJXp-mo" id="MJXp-Span-428" style="margin-left: 0em; margin-right: 0em;">[</span><span class="MJXp-msubsup" id="MJXp-Span-429"><span class="MJXp-mi" id="MJXp-Span-430" style="margin-right: 0.05em;">Σ</span><span class="MJXp-script-box" style="height: 1.86em; vertical-align: -0.64em;"><span class="MJXp-script"><span><span style="margin-bottom: -0.25em;"><span class="MJXp-mi" id="MJXp-Span-435">∞</span></span></span></span><span class="MJXp-script"><span><span style="margin-top: -0.85em;"><span class="MJXp-mrow" id="MJXp-Span-431"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-432">k</span><span class="MJXp-mo" id="MJXp-Span-433">=</span><span class="MJXp-mn" id="MJXp-Span-434">0</span></span></span></span></span></span></span><span class="MJXp-msubsup" id="MJXp-Span-436"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-437" style="margin-right: 0.05em;">γ</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-438" style="vertical-align: 0.5em;">k</span></span><span class="MJXp-msubsup" id="MJXp-Span-439"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-440" style="margin-right: 0.05em;">R</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-441" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-442">t</span><span class="MJXp-mo" id="MJXp-Span-443">+</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-444">k</span><span class="MJXp-mo" id="MJXp-Span-445">+</span><span class="MJXp-mn" id="MJXp-Span-446">1</span></span></span><span class="MJXp-mrow" id="MJXp-Span-447"><span class="MJXp-mo" id="MJXp-Span-448" style="margin-left: 0.167em; margin-right: 0.167em;">|</span></span><span class="MJXp-msubsup" id="MJXp-Span-449"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-450" style="margin-right: 0.05em;">S</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-451" style="vertical-align: -0.4em;">t</span></span><span class="MJXp-mo" id="MJXp-Span-452" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-453">s</span><span class="MJXp-mo" id="MJXp-Span-454" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-msubsup" id="MJXp-Span-455"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-456" style="margin-right: 0.05em;">A</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-457" style="vertical-align: -0.4em;">t</span></span><span class="MJXp-mo" id="MJXp-Span-458" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-459">a</span><span class="MJXp-mo" id="MJXp-Span-460" style="margin-left: 0em; margin-right: 0em;">]</span></span></span><script type="math/tex" id="MathJax-Element-46">q_\pi(s, a) = \mathbb{E}_\pi[\Sigma_{k=0}^\infty \gamma^k R_{t+k+1} | S_t = s, A_t = a]</script></span><span>.</span></p><p><span>This seemingly insignificant distinction will help us when it comes time to compute the optimal policy </span><span class="mathjax raw"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-461"><span class="MJXp-msubsup" id="MJXp-Span-462"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-463" style="margin-right: 0.05em;">π</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-464" style="vertical-align: -0.4em;"><span class="MJXp-mo" id="MJXp-Span-465">∗</span></span></span><span class="MJXp-mo" id="MJXp-Span-466" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mo" id="MJXp-Span-467" style="margin-left: 0.267em; margin-right: 0.267em;">⋅</span><span class="MJXp-mo" id="MJXp-Span-468" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><script type="math/tex" id="MathJax-Element-47">\pi_{*}(\cdot)</script></span><span>. Together, the state-value and action-value functions, are called the Bellman equations. We, will now solve for the value of these Bellman equations at each state or state-action pair, using two fundamental algorithms.</span></p><h3 id="Solving-via-Policy-Iteration" data-id="Solving-via-Policy-Iteration"><a class="anchor hidden-xs" href="#Solving-via-Policy-Iteration" title="Solving-via-Policy-Iteration"><span class="octicon octicon-link"></span></a><span>Solving via Policy Iteration</span></h3><p><span>The first main algorithm used to solve finite MDPs is called Policy Iteration. This algorithm iterates between two steps. The first step is to evaluate the value function for all states of an MDP given an arbitrary policy. This is commonly referred to as </span><em><span>policy evaluation</span></em><span>. The second step is to consider for each state, whether taking action </span><span class="mathjax raw"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-469"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-470">a</span><span class="MJXp-mo" id="MJXp-Span-471" style="margin-left: 0.333em; margin-right: 0.333em;">≠</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-472">π</span><span class="MJXp-mo" id="MJXp-Span-473" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-474">s</span><span class="MJXp-mo" id="MJXp-Span-475" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><script type="math/tex" id="MathJax-Element-48">a \neq \pi(s)</script></span><span> (not part of the policy) can improve the overall expected return. This is commonly referred to as </span><em><span>policy evaluation</span></em><span>. The algorithm loops through these steps, finding a better policy at each iteration until convergence.</span></p><p><span>Now, we shall implement Markov’s model world using python and numpy. We follow the standard algorithm implementation outlined in Richard Sutton’s RL </span><a href="http://incompleteideas.net/book/first/ebook/node40.html" target="_blank" rel="noopener"><span>textbook</span></a><span>. However, we make a few simplificiations for a quick build. (1) Our model only has 1 reward per (s’, s, a) pairs, while others allow for a distribution over rewards (2) We are searching to solve for a deterministic policy, while others can solve for a stochastic policy (3) Instead of defining 56 carefully engineered rewards and transitions, we assign fixed values (4) To assure convergence of our expected long term reward (to avoid values approaching infinity), so we include a discount rate of 0.85.</span></p><p><span>We first need to make a few imports and initialize our finite MDP.</span></p><pre><code class="python hljs"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
<span class="hljs-keyword">import</span> math

states = <span class="hljs-number">3</span> <span class="hljs-comment">#Number of States</span>
actions = <span class="hljs-number">3</span> <span class="hljs-comment">#Number of Actions</span>
rewards = <span class="hljs-number">3</span> <span class="hljs-comment">#Number of Rewards per State-action Pair</span>
g = <span class="hljs-number">0.85</span> <span class="hljs-comment">#Discount Rate - gamma</span>
v_s = [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>] <span class="hljs-comment">#State-value Function</span>
pi = [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>] <span class="hljs-comment">#Deterministic Policy Function</span>
theta = <span class="hljs-number">1</span> <span class="hljs-comment">#Hyperparameter</span>
np.random.seed(<span class="hljs-number">0</span>) <span class="hljs-comment">#Random seed used to initalize Reward Function</span>
R = <span class="hljs-number">100</span> * np.random.rand(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>) <span class="hljs-comment">#Reward Function: intialize a 3x3x3 tensor of random values from 0 to 100</span>
T = np.full((<span class="hljs-number">3</span>,<span class="hljs-number">3</span>,<span class="hljs-number">3</span>), <span class="hljs-number">1</span>/<span class="hljs-number">3</span>) <span class="hljs-comment">#Transition Function: intialize a 3x3x3 tensor of 1/3s</span>
PI = [] <span class="hljs-comment">#List to keep track of value function for Policy Iteration</span>
VI = [] <span class="hljs-comment">#List to keep track of value function for Value Iteration</span>
<span class="hljs-built_in">print</span>(R) <span class="hljs-comment">#Our specific Reward Function</span>

<span class="hljs-comment">#Randomly Initialized Reward Function</span>
[[[<span class="hljs-number">0.5488135</span>  <span class="hljs-number">0.71518937</span> <span class="hljs-number">0.60276338</span>]
  [<span class="hljs-number">0.54488318</span> <span class="hljs-number">0.4236548</span>  <span class="hljs-number">0.64589411</span>]
  [<span class="hljs-number">0.43758721</span> <span class="hljs-number">0.891773</span>   <span class="hljs-number">0.96366276</span>]]

 [[<span class="hljs-number">0.38344152</span> <span class="hljs-number">0.79172504</span> <span class="hljs-number">0.52889492</span>]
  [<span class="hljs-number">0.56804456</span> <span class="hljs-number">0.92559664</span> <span class="hljs-number">0.07103606</span>]
  [<span class="hljs-number">0.0871293</span>  <span class="hljs-number">0.0202184</span>  <span class="hljs-number">0.83261985</span>]]

 [[<span class="hljs-number">0.77815675</span> <span class="hljs-number">0.87001215</span> <span class="hljs-number">0.97861834</span>]
  [<span class="hljs-number">0.79915856</span> <span class="hljs-number">0.46147936</span> <span class="hljs-number">0.78052918</span>]
  [<span class="hljs-number">0.11827443</span> <span class="hljs-number">0.63992102</span> <span class="hljs-number">0.14335329</span>]]]
</code></pre><p><span>Now for the implementation of Policy Iteration, which initializes an arbitraty policy and state-value function, then iterates between policy evaluation and policy improvement stages.</span></p><pre><code class="python hljs"><span class="hljs-keyword">def</span> <span class="hljs-title function_">policy_iteration</span>(<span class="hljs-params">pol, val, thres</span>):
  <span class="hljs-comment">#Initialize Policy and Value Function</span>
  policy = pol 
  threshold = thres
  v_s_init = val
  PI.append(v_s_init.copy())
  <span class="hljs-comment">#Run first iteration of PE to evaluate your arbitrary policy</span>
  value = policy_evaluation(pi, v_s_init, threshold)
  PI.append(value.copy())
  <span class="hljs-comment">#Run first iteration of PI to find actions that might prove it</span>
  policy_stable, policy = policy_improvement(pi, value)
  <span class="hljs-comment">#Repeat PE and PI, until no change in policy improves performance (i.e. policy_stable = True)</span>
  <span class="hljs-keyword">while</span> policy_stable == <span class="hljs-literal">False</span>:
    value = policy_evaluation(policy, value, threshold)
    PI.append(value.copy())
    policy_stable, policy = policy_improvement(policy, value)
  <span class="hljs-keyword">return</span> policy, value

<span class="hljs-keyword">def</span> <span class="hljs-title function_">policy_evaluation</span>(<span class="hljs-params">pol, val, thres</span>):
  policy = pol
  threshold = thres
  v_s_init = val
  delta = math.inf
  <span class="hljs-comment">#Evalute accuracy until Delta drops below specified threshold value</span>
  <span class="hljs-keyword">while</span> delta &gt;= threshold:
    delta = <span class="hljs-number">0</span>
    <span class="hljs-comment">#Compute expected return for each state, given the current policy</span>
    <span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(states):
      v = v_s_init[s]
      E_r = <span class="hljs-number">0</span>
      <span class="hljs-keyword">for</span> s_p <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(states):
        E_r += T[s, policy[s], s_p]*(R[s, policy[s], s_p] + g*v_s_init[s_p])
      v_s_init[s] = E_r
      delta = <span class="hljs-built_in">max</span>(delta, <span class="hljs-built_in">abs</span>(v - v_s_init[s]))
  <span class="hljs-keyword">return</span> v_s_init

<span class="hljs-keyword">def</span> <span class="hljs-title function_">policy_improvement</span>(<span class="hljs-params">pol, val</span>):
  policy_stable = <span class="hljs-literal">True</span>
  policy = pol.copy()
  v_s_init = val
  <span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(states):
    old_a = pol[s]
    v = v_s_init[s]
    E_r = []
    <span class="hljs-comment">#Evalute expected value of each state and action pair</span>
    <span class="hljs-keyword">for</span> a <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(actions):
      e_r = <span class="hljs-number">0</span>
      <span class="hljs-keyword">for</span> s_p <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(states):
        e_r += T[s, a, s_p]*(R[s, a, s_p] + g*v_s_init[s_p])
      E_r.append(e_r)
      <span class="hljs-comment">#Select action the maximizes expected value</span>
      new_a = E_r.index(<span class="hljs-built_in">max</span>(E_r))
      <span class="hljs-comment">#Compare if action that maximizes expected value is action specified by current policy</span>
      <span class="hljs-keyword">if</span>(old_a != new_a):
        <span class="hljs-comment">#If not, modify policy and report stability to false, to ensure PI evalutes new policy</span>
        policy[s] = new_a
        policy_stable = <span class="hljs-literal">False</span>
  <span class="hljs-keyword">return</span> policy_stable, policy
<span class="hljs-comment">#Run Algorithm</span>
new_pi, new_v = value_iteration(pi, v_s, theta)
</code></pre><p><img src="https://i.imgur.com/7Z9j6T0.png" alt="" loading="lazy"><br>
<span>Algorithm Output:</span><br>
<span class="mathjax raw"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-476"><span class="MJXp-msubsup" id="MJXp-Span-477"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-478" style="margin-right: 0.05em;">v</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-479" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-480">π</span><span class="MJXp-mo" id="MJXp-Span-481">∗</span></span></span><span class="MJXp-mo" id="MJXp-Span-482" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-483"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-484" style="margin-right: 0.05em;">s</span><span class="MJXp-mn MJXp-script" id="MJXp-Span-485" style="vertical-align: -0.4em;">1</span></span><span class="MJXp-mo" id="MJXp-Span-486" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-msubsup" id="MJXp-Span-487"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-488" style="margin-right: 0.05em;">s</span><span class="MJXp-mn MJXp-script" id="MJXp-Span-489" style="vertical-align: -0.4em;">2</span></span><span class="MJXp-mo" id="MJXp-Span-490" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-msubsup" id="MJXp-Span-491"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-492" style="margin-right: 0.05em;">s</span><span class="MJXp-mn MJXp-script" id="MJXp-Span-493" style="vertical-align: -0.4em;">3</span></span><span class="MJXp-mo" id="MJXp-Span-494" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><script type="math/tex" id="MathJax-Element-49">v_{\pi*}(s_1, s_2, s_3)</script></span><span> = [489.98445020171096, 470.622736297478, 501.629766335168]</span><br>
<span class="mathjax raw"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-495"><span class="MJXp-msubsup" id="MJXp-Span-496"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-497" style="margin-right: 0.05em;">π</span><span class="MJXp-mo MJXp-script" id="MJXp-Span-498" style="vertical-align: -0.4em;">∗</span></span><span class="MJXp-mo" id="MJXp-Span-499" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-500"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-501" style="margin-right: 0.05em;">s</span><span class="MJXp-mn MJXp-script" id="MJXp-Span-502" style="vertical-align: -0.4em;">1</span></span><span class="MJXp-mo" id="MJXp-Span-503" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-msubsup" id="MJXp-Span-504"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-505" style="margin-right: 0.05em;">s</span><span class="MJXp-mn MJXp-script" id="MJXp-Span-506" style="vertical-align: -0.4em;">2</span></span><span class="MJXp-mo" id="MJXp-Span-507" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-msubsup" id="MJXp-Span-508"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-509" style="margin-right: 0.05em;">s</span><span class="MJXp-mn MJXp-script" id="MJXp-Span-510" style="vertical-align: -0.4em;">3</span></span><span class="MJXp-mo" id="MJXp-Span-511" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><script type="math/tex" id="MathJax-Element-50">\pi_*(s_1, s_2, s_3)</script></span><span> = [2, 0, 0]</span></p><p><span>By running this algorithm, we obtain the optimal state-value function and optimal policy shown above. Now this example is clearly idealistic, we are given the states, actions, and rewards. In the real world we don’t have this, and real world problems are typically much more complicated. Figuring out how to solve more complex, obscure problems is an open challenge that the field faces to this day. In short, MDPs solve real-world problems only as best as you can model problems in the first place. Therefore, although we may not be able gaurantee that our policy will help Markov in the real-world, we hope that the theoretical implications can provide insight into his decision making.</span></p><h3 id="Solving-via-Value-Iteration-and-More" data-id="Solving-via-Value-Iteration-and-More"><a class="anchor hidden-xs" href="#Solving-via-Value-Iteration-and-More" title="Solving-via-Value-Iteration-and-More"><span class="octicon octicon-link"></span></a><span>Solving via Value Iteration and More</span></h3><p><span>Now, let’s attempt to find the optimal policy of out student’s Markov’s work using Value Iteration. The structure of this algorithm is very similar to Policy Iteration, but differs slightly. Instead of iterating back and forth between improvement and evaluation in Policy Iteration, Value Iteration performs a single iteration of a pseudo policy evaluation, where it additionally sweeps over the action space and perform a max operation to return the optimal state-value function and policy function upon completion.</span></p><pre><code class="python hljs"><span class="hljs-keyword">def</span> <span class="hljs-title function_">value_iteration</span>(<span class="hljs-params">pol, val, thres</span>):
  <span class="hljs-comment">#Initialize Policy and Value Function</span>
  policy = pol
  threshold = thres
  v_s_init = val
  VI.append(v_s_init.copy())
  delta = math.inf
  <span class="hljs-comment">#Loop until delta reaches specified threshold</span>
  <span class="hljs-keyword">while</span> delta &gt;= threshold:
    delta = <span class="hljs-number">0</span>
    <span class="hljs-comment">#Evalute expected value of each state and action pair</span>
    <span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(states):
      v = v_s_init[s]
      E_r = []
      <span class="hljs-keyword">for</span> a <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(actions):
        e_r = <span class="hljs-number">0</span>
        <span class="hljs-keyword">for</span> s_p <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(states):
          e_r += T[s, a, s_p]*(R[s, a, s_p] + g*v_s_init[s_p])
        E_r.append(e_r)
      <span class="hljs-comment">#Update policy with action that maximizes return</span>
      policy[s] = E_r.index(<span class="hljs-built_in">max</span>(E_r))
      <span class="hljs-comment">#Update new state-value function accordingly</span>
      v_s_init[s] = <span class="hljs-built_in">max</span>(E_r)
      delta = <span class="hljs-built_in">max</span>(delta, <span class="hljs-built_in">abs</span>(v - v_s_init[s]))
    I.append(v_s_init.copy())
  <span class="hljs-keyword">return</span> policy, v_s_init
<span class="hljs-comment">#Run Algorithm</span>
new_pi, new_v = value_iteration(pi, v_s, theta)
</code></pre><p><img src="https://i.imgur.com/nJZINsd.png" alt="" loading="lazy"><br>
<span>Algorithm Ouput:</span><br>
<span class="mathjax raw"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-512"><span class="MJXp-msubsup" id="MJXp-Span-513"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-514" style="margin-right: 0.05em;">v</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-515" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-516">π</span><span class="MJXp-mo" id="MJXp-Span-517">∗</span></span></span><span class="MJXp-mo" id="MJXp-Span-518" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-519"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-520" style="margin-right: 0.05em;">s</span><span class="MJXp-mn MJXp-script" id="MJXp-Span-521" style="vertical-align: -0.4em;">1</span></span><span class="MJXp-mo" id="MJXp-Span-522" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-msubsup" id="MJXp-Span-523"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-524" style="margin-right: 0.05em;">s</span><span class="MJXp-mn MJXp-script" id="MJXp-Span-525" style="vertical-align: -0.4em;">2</span></span><span class="MJXp-mo" id="MJXp-Span-526" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-msubsup" id="MJXp-Span-527"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-528" style="margin-right: 0.05em;">s</span><span class="MJXp-mn MJXp-script" id="MJXp-Span-529" style="vertical-align: -0.4em;">3</span></span><span class="MJXp-mo" id="MJXp-Span-530" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><script type="math/tex" id="MathJax-Element-51">v_{\pi*}(s_1, s_2, s_3)</script></span><span> = [490.2756261387957, 470.8914747627405, 501.8777964782847]</span><br>
<span class="mathjax raw"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-531"><span class="MJXp-msubsup" id="MJXp-Span-532"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-533" style="margin-right: 0.05em;">π</span><span class="MJXp-mo MJXp-script" id="MJXp-Span-534" style="vertical-align: -0.4em;">∗</span></span><span class="MJXp-mo" id="MJXp-Span-535" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-536"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-537" style="margin-right: 0.05em;">s</span><span class="MJXp-mn MJXp-script" id="MJXp-Span-538" style="vertical-align: -0.4em;">1</span></span><span class="MJXp-mo" id="MJXp-Span-539" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-msubsup" id="MJXp-Span-540"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-541" style="margin-right: 0.05em;">s</span><span class="MJXp-mn MJXp-script" id="MJXp-Span-542" style="vertical-align: -0.4em;">2</span></span><span class="MJXp-mo" id="MJXp-Span-543" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-msubsup" id="MJXp-Span-544"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-545" style="margin-right: 0.05em;">s</span><span class="MJXp-mn MJXp-script" id="MJXp-Span-546" style="vertical-align: -0.4em;">3</span></span><span class="MJXp-mo" id="MJXp-Span-547" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><script type="math/tex" id="MathJax-Element-52">\pi_*(s_1, s_2, s_3)</script></span><span> = [2, 0, 0]</span></p><p><span>By running this algorithm, we obtain the optimal state-value function and optimal policy shown above. Overall, both methods follow different paths to reach the same solution, each carefully designed to use the Bellman equations to better understand the MDP.</span></p><h3 id="Conclusion" data-id="Conclusion"><a class="anchor hidden-xs" href="#Conclusion" title="Conclusion"><span class="octicon octicon-link"></span></a><span>Conclusion</span></h3><p><span>This blog only covers the basics, and there is much more to explore in MDP theory. For example, there exists many extensions and generalizations to this framework, such as the partially observed or continous cases, studied by mathematicians and engineers alike. If this blog interested you and you want to dive deeper into algorithms for solving finite, discrete markov chains, then take a look at the references for a more detailed treatment of the topic.</span></p><h3 id="References-and-Future-Readings" data-id="References-and-Future-Readings"><a class="anchor hidden-xs" href="#References-and-Future-Readings" title="References-and-Future-Readings"><span class="octicon octicon-link"></span></a><span>References and Future Readings</span></h3><h4 id="Key-Survey-Reads" data-id="Key-Survey-Reads"><a class="anchor hidden-xs" href="#Key-Survey-Reads" title="Key-Survey-Reads"><span class="octicon octicon-link"></span></a><span>Key Survey Reads</span></h4><p><span>Introduction in Reinforcment Learning by Sutton and Barto, Chapters 3 and 4*</span><br>
<span>Probability in Electrical Engineering and Computer Science by Jean Walrand, Chapters 11 and 12</span><br>
<span>Dynamic Programming and Markov Processes by Ronald Howard</span><br>
<a href="https://en.wikipedia.org/wiki/Deep_reinforcement_learning" target="_blank" rel="noopener"><span>https://en.wikipedia.org/wiki/Deep_reinforcement_learning</span></a><br>
<a href="https://en.wikipedia.org/wiki/Markov_decision_process" target="_blank" rel="noopener"><span>https://en.wikipedia.org/wiki/Markov_decision_process</span></a><br>
<a href="http://incompleteideas.net/" target="_blank" rel="noopener"><span>http://incompleteideas.net/</span></a><br>
<span>*Read Bibliographical and Historial Remarks for a deeper dive</span></p><h4 id="Related-Slides-and-Class-Sites" data-id="Related-Slides-and-Class-Sites"><a class="anchor hidden-xs" href="#Related-Slides-and-Class-Sites" title="Related-Slides-and-Class-Sites"><span class="octicon octicon-link"></span></a><span>Related Slides and Class Sites</span></h4><p><a href="https://web.stanford.edu/class/cme241/lecture_slides/rich_sutton_slides/5-6-MDPs.pdf" target="_blank" rel="noopener"><span>https://web.stanford.edu/class/cme241/lecture_slides/rich_sutton_slides/5-6-MDPs.pdf</span></a><br>
<a href="https://inst.eecs.berkeley.edu/~cs188/sp20/assets/lecture/lec10.pdf" target="_blank" rel="noopener"><span>https://inst.eecs.berkeley.edu/~cs188/sp20/assets/lecture/lec10.pdf</span></a><br>
<a href="https://people.eecs.berkeley.edu/~pabbeel/cs287-fa12/slides/mdps-exact-methods.pdf" target="_blank" rel="noopener"><span>https://people.eecs.berkeley.edu/~pabbeel/cs287-fa12/slides/mdps-exact-methods.pdf</span></a><br>
<a href="https://people.eecs.berkeley.edu/~pabbeel/cs287-fa12/" target="_blank" rel="noopener"><span>https://people.eecs.berkeley.edu/~pabbeel/cs287-fa12/</span></a><br>
<a href="https://www.cse.iitb.ac.in/~shivaram/resources/ijcai-2017-tutorial-policyiteration/tapi.pdf" target="_blank" rel="noopener"><span>https://www.cse.iitb.ac.in/~shivaram/resources/ijcai-2017-tutorial-policyiteration/tapi.pdf</span></a><br>
<a href="https://homes.cs.washington.edu/~todorov//courses/amath579/MDP.pdf" target="_blank" rel="noopener"><span>https://homes.cs.washington.edu/~todorov//courses/amath579/MDP.pdf</span></a><br>
<a href="https://www.tau.ac.il/~mansour/rl.html" target="_blank" rel="noopener"><span>https://www.tau.ac.il/~mansour/rl.html</span></a><br>
<a href="https://www.cs.mcgill.ca/~dprecup/courses/AI/Lectures/ai-lecture16.pdf" target="_blank" rel="noopener"><span>https://www.cs.mcgill.ca/~dprecup/courses/AI/Lectures/ai-lecture16.pdf</span></a></p><h4 id="Niche-Intersecting-Reads" data-id="Niche-Intersecting-Reads"><a class="anchor hidden-xs" href="#Niche-Intersecting-Reads" title="Niche-Intersecting-Reads"><span class="octicon octicon-link"></span></a><span>Niche Intersecting Reads</span></h4><p><a href="https://en.wikipedia.org/wiki/Markov_decision_process#Extensions_and_generalizations" target="_blank" rel="noopener"><span>https://en.wikipedia.org/wiki/Markov_decision_process#Extensions_and_generalizations</span></a><br>
<a href="https://arxiv.org/pdf/1302.4971.pdf" target="_blank" rel="noopener"><span>https://arxiv.org/pdf/1302.4971.pdf</span></a><br>
<a href="http://incompleteideas.net/RandomMDPs.html" target="_blank" rel="noopener"><span>http://incompleteideas.net/RandomMDPs.html</span></a></p><h4 id="Talks" data-id="Talks"><a class="anchor hidden-xs" href="#Talks" title="Talks"><span class="octicon octicon-link"></span></a><span>Talks</span></h4><p><a href="https://www.youtube.com/watch?v=vY-voHb22io&amp;list=PLKlhhkvvU8-aXmPQZNYG_e-2nTd0tJE8v&amp;index=35&amp;t=0s" target="_blank" rel="noopener"><span>https://www.youtube.com/watch?v=vY-voHb22io&amp;list=PLKlhhkvvU8-aXmPQZNYG_e-2nTd0tJE8v&amp;index=35&amp;t=0s</span></a></p><h5 id="Other-Blogs" data-id="Other-Blogs"><a class="anchor hidden-xs" href="#Other-Blogs" title="Other-Blogs"><span class="octicon octicon-link"></span></a><span>Other Blogs</span></h5><p><a href="https://towardsdatascience.com/introduction-to-reinforcement-learning-markov-decision-process-44c533ebf8da" target="_blank" rel="noopener"><span>https://towardsdatascience.com/introduction-to-reinforcement-learning-markov-decision-process-44c533ebf8da</span></a><span> (3 part series)</span></p></div>
    <div class="ui-toc dropup unselectable hidden-print" style="display:none;">
        <div class="pull-right dropdown">
            <a id="tocLabel" class="ui-toc-label btn btn-default" data-toggle="dropdown" href="#" role="button" aria-haspopup="true" aria-expanded="false" title="Table of content">
                <i class="fa fa-bars"></i>
            </a>
            <ul id="ui-toc" class="ui-toc-dropdown dropdown-menu" aria-labelledby="tocLabel">
                <div class="toc"><ul class="nav">
<li><a href="#What-are-MDPs-And-how-can-we-Solve-them" title="What are MDPs? And how can we Solve them?">What are MDPs? And how can we Solve them?</a><ul class="nav">
<li><a href="#Introduction" title="Introduction">Introduction</a><ul class="nav">
<li><a href="#Mr-Markov-Navigating-College" title="Mr. Markov Navigating College">Mr. Markov Navigating College</a></li>
<li><a href="#Modeling-Mr-Markov’s-World" title="Modeling Mr. Markov’s World">Modeling Mr. Markov’s World</a></li>
<li><a href="#Recap-of-Definitions" title="Recap of Definitions">Recap of Definitions</a></li>
<li><a href="#More-Fun-Functions" title="More Fun Functions">More Fun Functions</a></li>
<li><a href="#Solving-via-Policy-Iteration" title="Solving via Policy Iteration">Solving via Policy Iteration</a></li>
<li><a href="#Solving-via-Value-Iteration-and-More" title="Solving via Value Iteration and More">Solving via Value Iteration and More</a></li>
<li><a href="#Conclusion" title="Conclusion">Conclusion</a></li>
<li><a href="#References-and-Future-Readings" title="References and Future Readings">References and Future Readings</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div><div class="toc-menu"><a class="expand-toggle" href="#">Expand all</a><a class="back-to-top" href="#">Back to top</a><a class="go-to-bottom" href="#">Go to bottom</a></div>
            </ul>
        </div>
    </div>
    <div id="ui-toc-affix" class="ui-affix-toc ui-toc-dropdown unselectable hidden-print" data-spy="affix" style="top:17px;display:none;" null null>
        <div class="toc"><ul class="nav">
<li><a href="#What-are-MDPs-And-how-can-we-Solve-them" title="What are MDPs? And how can we Solve them?">What are MDPs? And how can we Solve them?</a><ul class="nav">
<li><a href="#Introduction" title="Introduction">Introduction</a><ul class="nav">
<li><a href="#Mr-Markov-Navigating-College" title="Mr. Markov Navigating College">Mr. Markov Navigating College</a></li>
<li><a href="#Modeling-Mr-Markov’s-World" title="Modeling Mr. Markov’s World">Modeling Mr. Markov’s World</a></li>
<li><a href="#Recap-of-Definitions" title="Recap of Definitions">Recap of Definitions</a></li>
<li><a href="#More-Fun-Functions" title="More Fun Functions">More Fun Functions</a></li>
<li><a href="#Solving-via-Policy-Iteration" title="Solving via Policy Iteration">Solving via Policy Iteration</a></li>
<li><a href="#Solving-via-Value-Iteration-and-More" title="Solving via Value Iteration and More">Solving via Value Iteration and More</a></li>
<li><a href="#Conclusion" title="Conclusion">Conclusion</a></li>
<li><a href="#References-and-Future-Readings" title="References and Future Readings">References and Future Readings</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div><div class="toc-menu"><a class="expand-toggle" href="#">Expand all</a><a class="back-to-top" href="#">Back to top</a><a class="go-to-bottom" href="#">Go to bottom</a></div>
    </div>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.1.1/jquery.min.js" integrity="sha256-hVVnYaiADRTO2PzUGmuLJr8BLUSjGIZsDYGmIJLv2b8=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8=" crossorigin="anonymous" defer></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/gist-embed/2.6.0/gist-embed.min.js" integrity="sha256-KyF2D6xPIJUW5sUDSs93vWyZm+1RzIpKCexxElmxl8g=" crossorigin="anonymous" defer></script>
    <script>
        var markdown = $(".markdown-body");
        //smooth all hash trigger scrolling
        function smoothHashScroll() {
            var hashElements = $("a[href^='#']").toArray();
            for (var i = 0; i < hashElements.length; i++) {
                var element = hashElements[i];
                var $element = $(element);
                var hash = element.hash;
                if (hash) {
                    $element.on('click', function (e) {
                        // store hash
                        var hash = this.hash;
                        if ($(hash).length <= 0) return;
                        // prevent default anchor click behavior
                        e.preventDefault();
                        // animate
                        $('body, html').stop(true, true).animate({
                            scrollTop: $(hash).offset().top
                        }, 100, "linear", function () {
                            // when done, add hash to url
                            // (default click behaviour)
                            window.location.hash = hash;
                        });
                    });
                }
            }
        }

        smoothHashScroll();
        var toc = $('.ui-toc');
        var tocAffix = $('.ui-affix-toc');
        var tocDropdown = $('.ui-toc-dropdown');
        //toc
        tocDropdown.click(function (e) {
            e.stopPropagation();
        });

        var enoughForAffixToc = true;

        function generateScrollspy() {
            $(document.body).scrollspy({
                target: ''
            });
            $(document.body).scrollspy('refresh');
            if (enoughForAffixToc) {
                toc.hide();
                tocAffix.show();
            } else {
                tocAffix.hide();
                toc.show();
            }
            $(document.body).scroll();
        }

        function windowResize() {
            //toc right
            var paddingRight = parseFloat(markdown.css('padding-right'));
            var right = ($(window).width() - (markdown.offset().left + markdown.outerWidth() - paddingRight));
            toc.css('right', right + 'px');
            //affix toc left
            var newbool;
            var rightMargin = (markdown.parent().outerWidth() - markdown.outerWidth()) / 2;
            //for ipad or wider device
            if (rightMargin >= 133) {
                newbool = true;
                var affixLeftMargin = (tocAffix.outerWidth() - tocAffix.width()) / 2;
                var left = markdown.offset().left + markdown.outerWidth() - affixLeftMargin;
                tocAffix.css('left', left + 'px');
            } else {
                newbool = false;
            }
            if (newbool != enoughForAffixToc) {
                enoughForAffixToc = newbool;
                generateScrollspy();
            }
        }
        $(window).resize(function () {
            windowResize();
        });
        $(document).ready(function () {
            windowResize();
            generateScrollspy();
        });

        //remove hash
        function removeHash() {
            window.location.hash = '';
        }

        var backtotop = $('.back-to-top');
        var gotobottom = $('.go-to-bottom');

        backtotop.click(function (e) {
            e.preventDefault();
            e.stopPropagation();
            if (scrollToTop)
                scrollToTop();
            removeHash();
        });
        gotobottom.click(function (e) {
            e.preventDefault();
            e.stopPropagation();
            if (scrollToBottom)
                scrollToBottom();
            removeHash();
        });

        var toggle = $('.expand-toggle');
        var tocExpand = false;

        checkExpandToggle();
        toggle.click(function (e) {
            e.preventDefault();
            e.stopPropagation();
            tocExpand = !tocExpand;
            checkExpandToggle();
        })

        function checkExpandToggle () {
            var toc = $('.ui-toc-dropdown .toc');
            var toggle = $('.expand-toggle');
            if (!tocExpand) {
                toc.removeClass('expand');
                toggle.text('Expand all');
            } else {
                toc.addClass('expand');
                toggle.text('Collapse all');
            }
        }

        function scrollToTop() {
            $('body, html').stop(true, true).animate({
                scrollTop: 0
            }, 100, "linear");
        }

        function scrollToBottom() {
            $('body, html').stop(true, true).animate({
                scrollTop: $(document.body)[0].scrollHeight
            }, 100, "linear");
        }
    </script>
</body>

</html>
